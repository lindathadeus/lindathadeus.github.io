<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Survey of Existing Solutions in LLM | Linda Joe Thadeus </title> <meta name="author" content="Linda Joe Thadeus"> <meta name="description" content="A personal website. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lindathadeus.github.io/blog/2024/llm-in-sony/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Linda Joe Thadeus </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Survey of Existing Solutions in LLM</h1> <p class="post-meta"> Created in November 05, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   <a href="/blog/tag/future-of-work"> <i class="fa-solid fa-hashtag fa-sm"></i> future of work</a>   <a href="/blog/tag/emerging-technologies"> <i class="fa-solid fa-hashtag fa-sm"></i> emerging technologies</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   ·   <a href="/blog/category/llm"> <i class="fa-solid fa-tag fa-sm"></i> llm</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h3 id="1-executive-summary"><strong>1. Executive Summary</strong></h3> <p><strong>Purpose</strong>: The survey of existing solutions in LLM is conducted to know the structure of each solution in terms of cost, data, primary user of the solution, i.e. the environmental cost, hardware cost, human-power cost, input data, output data, input’s parameters like size, human-made or ai-generated, output parameters like quality, quality parameters like likeability by the readers, function on the likeability by the readers like how many readers liked how much, etc. It also defines various words used in the LLM, demystifying the meaning for the readers.<br> <strong>Scope</strong>: We will be covering the major parameters of different solutions at a high level. We will also do implementations for some of them.<br> <strong>Key Findings</strong>: The average user of LLM is an API/Cloud LLM user, for truly enjoying the LLM technology, one has to build LLMs from scratch and for best of the both worlds, one can opt for Hybrid ones.</p> <h3 id="2-introduction"><strong>2. Introduction</strong></h3> <p><strong>Background</strong>: Short description of the technology landscape and why this survey is relevant.</p> <p>Everything is a consequence of prior actions. LLMs emerged as a response to the high consumption of cloud computing resources and the exponential growth of unstructured data generated by users through platforms like social media and internet blogs. Initially, large amounts of unstructured data were held by internet companies, necessitating insights to benefit users directly.</p> <p>Some companies reportedly analyzed user data without consent, raising concerns about privacy and transparency. As a result, the need for consent and privacy protection became paramount. Companies relying on advertisements also had to understand user behavior to avoid alienating their audience. This led to the creation of intelligent systems that could collect, monitor, inspect, predict, and even generate data. Generative AI arose as a natural consequence of these developments. But, how would a common person use this AI effectively? How would it benefit them? What could happen if not?</p> <p><strong>Problem Statement</strong>: The problem with this is, there is too much data but not much awareness about the usage of generative AI LLM tools.</p> <p><strong>Objectives</strong>: What the paper aims to achieve is, to compare, evaluate, or identify trends in solutions, and also to structure the solutions.</p> <h3 id="3-methodology"><strong>3. Methodology</strong></h3> <p><strong>Research Approach</strong>:</p> <p>We believe that the correct way to learn a solution is to use it. So over a period of time. We used the different solutions and we gathered some interesting insights and found some methods were easier for some set of users than the others.</p> <p><strong>Evaluation Criteria</strong>: Key factors used to compare solutions are cost, ease of use.</p> <h3 id="4-overview-of-existing-solutions"><strong>4. Overview of Existing Solutions</strong></h3> <p><strong>Solution Categories</strong>: As per our perspective and our research on it so far, there are 3 types of LLMs available for use. The first one is the “Cloud-based” or “Hosted” LLM. The LLM could be hosted anywhere in the open internet, or closed. The existing ideas of private cloud, public cloud, on-premises cloud, apply here too. The Hugging face comes as the public cloud based on but it is built on top of open LLMs unlike OpenAI’s GPT that is based on closed dataset LLM GPT3 and above. They typically use API as the connection. The next one is building one from scratch and making it to our taste. The other solution is making a hybrid one. Take one existing LLM and finetune with our data. For this we would use a foundational LLM and give our custom data and interacting guidelines. So, There are 3 solutions available, the first one is API based existing LLM, the next one is Home-made LLM, and the third one is Hybrid LLM.</p> <p><strong>Key Players/Technologies</strong>: OpenAI ChatGPT, a very popular Chat-tuned LLM, LLAMA LLMs - a popular open distribution LLM but not open weight, Microsoft Phi LLM - a popular smaller LLM.</p> <h3 id="5-comparative-analysis"><strong>5. Comparative Analysis</strong></h3> <p><strong>API Based LLMs</strong>:</p> <ul> <li>Strengths</li> <li>Weaknesses</li> <li>Unique Features</li> </ul> <p>API based LLM: The first solution is the API based LLM. The most popular one amongst them is the ChatGPT by OpenAI. We would like to think of it as a Mainframe Supercomputer, where we have keyboard and dumb screens and our interaction is through these fancy wires called APIs. Now, we also have a voice mode, in future, we may also have a video mode and so on. Of-course there are different tiers where one can access these modes like, just using chat interface i.e. ChatGPT and create GPTs on top of them in their GPT store or through web services or through CLIs that would anyway have to contact these REST APIs. For the purpose of understanding these API based LLM, we created a GPT in 2 hours. Below is the GPT. So, this is the most accessible way for creating custom LLMs for our use. But, the drawbacks are obvious, we need to follow the RULES, specifically the rules given and managed by OpenAI.</p> <p>Eg GPT : Please check the appendix</p> <p><strong>Home-made LLMs</strong>:<br> Home-made LLM: These LLMs are purely made by the users from their local machine at home or anywhere they like. But, this requires the users to be technical, they have to have knowledge of LLMs, Python and even Linux for some cases where they use Linux developer setup. We would like to think of these LLMs as truly open and purposeful LLMs. Much like, when the internet technology opened the gate-keeped knowledge and gave to the world, but it also gave multiplication over the existing issues and made it easy for the users to fall prey to DISTRACTION if there was not a PURPOSE. But, this is the best use of an LLM. Because the users generate data and they know the pattern or the world view with which they generated the data, it would be easier to them than the middle man. So, this is less environmentally bothersome too. And, so, in our perspective, we think this as the TRUE by-product of this AI revolution if it were. But this method is not very accessible to the common users and more accessible to the Developers. So, the developers should make use of this. As part of understanding this type, we created an LLM, kinda, using the existing framework like pytorch and used a custom dataset.</p> <p><strong>Hybrid LLMs</strong>:<br> Hybrid LLM: This is the best of both worlds. This can be achieved easily with lesser time too unlike the “PURPOSEFUL LLMs” above. We downloaded the existing LLM from Hugging Face and did our prompting (and finetuning in progress) on that. This is also less accessible to common person and more suited for software engineers. As part of this survey, we downloaded a smaller LLM from Microsoft Phi Series and tried to work with that.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> 
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> 
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="sh">'</span><span class="s">accelerate\&gt;=0.26.0</span><span class="sh">'</span> 
<span class="err">$</span> <span class="n">python3</span> <span class="n">phi</span><span class="p">.</span><span class="n">py</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">microsoft/Phi-3.5-mini-instruct</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">device_map</span><span class="o">=</span><span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">torch_dtype</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
<span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">microsoft/Phi-3.5-mini-instruct</span><span class="sh">"</span><span class="p">)</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="nf">pipeline</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">text-generation</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Open and read the file
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">conversation_samples.txt</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">conversation</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">readlines</span><span class="p">()</span>

<span class="c1"># Initialize a list to store the conversation data
</span><span class="n">conversation_json</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Process each line
</span><span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">conversation</span><span class="p">:</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>  <span class="c1"># Remove any extra spaces or newline characters
</span>
    <span class="c1"># Check if the line starts with "User:" or "AI:"
</span>    <span class="k">if</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">User:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">User:</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>
        <span class="n">conversation_json</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>
    <span class="k">elif</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">AI:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">AI:</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>
        <span class="n">conversation_json</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>

<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">You are a helpful AI Emotions Stabilizer. The Emotions Stabilizer is designed to provide empathetic, structured guidance for processing emotions, adapting to the user</span><span class="sh">'</span><span class="s">s needs while ensuring each conversation has a clear, progressive flow. Acting as a supportive mentor, the Emotions Stabilizer helps users process both positive and negative emotions by following a structured set of questions. It provides prompts one at a time and waits for each response,acknowledging and validating the user</span><span class="sh">'</span><span class="s">s experience before moving forward. The Emotions Stabilizer aims to keep conversations focused and purposeful, minimizing unnecessary steps to help the user feel a sense of progress and completion.The Emotions Stabilizer will acknowledge user responses concisely to avoid overly lengthy dialogues and unfocused dialogues, guiding each step in a way that maximizes clarity and momentum. If the user seems ready to let go or wishes to end the conversation, the Emotions Stabilizer will respect this, encouraging closure in a supportive, empowering tone. For simplicity, the Emotions Stabilizer will focus as only positive and negative, and group all emotions under this with an intensity</span><span class="sh">"</span><span class="p">}</span>
<span class="p">]</span>

<span class="n">messages</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">conversation_json</span><span class="p">)</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
	<span class="n">user_input</span> <span class="o">=</span> <span class="nf">input</span><span class="p">(</span><span class="sh">"</span><span class="s">Press quit or exit to quit</span><span class="se">\n\n</span><span class="s">User: </span><span class="sh">"</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">user_input</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">exit</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">quit</span><span class="sh">"</span><span class="p">]:</span>
		<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Ending conversation.</span><span class="sh">"</span><span class="p">)</span>
		<span class="k">break</span>

	<span class="n">messages</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">user_input</span><span class="p">})</span>

	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">response</span> <span class="o">=</span> <span class="nf">pipe</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_full_text</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">generated_text</span><span class="sh">'</span><span class="p">]</span>

	<span class="n">messages</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">response</span><span class="p">})</span>

	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">AI: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> <hr> <p><strong>Appendix</strong> <a href="https://chatgpt.com/g/g-wjwrMf1LL-emotions-stabilizer" rel="external nofollow noopener" target="_blank">https://chatgpt.com/g/g-wjwrMf1LL-emotions-stabilizer</a></p> <hr> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below. Together, we can navigate this evolving landscape and find our place in the future of work.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/linux-self-learning/">How to self-learn Linux?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/worthy-word-securely-attached/">Worthy Word #2 Securely Attached</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/key-debugging/">Debugging Keyboard events in Sony Laptop</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/linux-compilation/">Compiling Linux for Sony Laptop from a ThinkPad</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/actions-trump-intentions/">AI Conversations: Actions and Words and Thoughts</a> </li> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"lindathadeus/lindathadeus.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Linda Joe Thadeus. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-YYWE00WWCH"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-YYWE00WWCH");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-survey-of-existing-solutions-in-llm",title:"Survey of Existing Solutions in LLM",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/llm-in-sony/"}},{id:"post-how-to-self-learn-linux",title:"How to self-learn Linux?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/linux-self-learning/"}},{id:"post-worthy-word-2-securely-attached",title:"Worthy Word #2 Securely Attached",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/worthy-word-securely-attached/"}},{id:"post-debugging-keyboard-events-in-sony-laptop",title:"Debugging Keyboard events in Sony Laptop",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/key-debugging/"}},{id:"post-compiling-linux-for-sony-laptop-from-a-thinkpad",title:"Compiling Linux for Sony Laptop from a ThinkPad",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/linux-compilation/"}},{id:"post-ai-conversations-actions-and-words-and-thoughts",title:"AI Conversations: Actions and Words and Thoughts",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/actions-trump-intentions/"}},{id:"post-scarcity-to-abundance-our-revolutions",title:"Scarcity to Abundance: Our Revolutions",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/revolution-sequence/"}},{id:"post-understanding-abi",title:"Understanding ABI",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/understanding-abi/"}},{id:"post-how-to-run-llm-on-a-laptop",title:"How to run LLM on a laptop?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/understanding-abi-1/"}},{id:"post-how-to-transition-from-surviving-to-living",title:"How to transition from surviving to living?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/surviving-living/"}},{id:"post-how-i-transitioned-from-surviving-to-living",title:"How I transitioned from surviving to living?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/surviving-living-orig/"}},{id:"post-can-we-use-the-reasoning-ai-model-for-dsa-practice",title:"Can we use the reasoning AI model for DSA Practice?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/dsa-training-ai/"}},{id:"post-how-to-navigate-the-trust-less-world",title:"How to navigate the trust less world?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/trustless-world/"}},{id:"post-what-happened-to-me-childhood",title:"What happened to me - childhood?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/my-hard-childhood/"}},{id:"post-how-to-run-llm-on-a-laptop",title:"How to run LLM on a laptop?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/llm-1-post/"}},{id:"post-why-words-are-not-enough",title:"Why Words Are Not Enough?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/words-not-inclusive/"}},{id:"post-second-brain-management-is-the-worst",title:"Second Brain Management is the WORST",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/second-brain-emotional-issues-post/"}},{id:"post-who-are-responsible-for-an-abuse",title:"Who are Responsible for an Abuse?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/actors-in-abuse-post/"}},{id:"post-worthy-word-1",title:"Worthy Word #1",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/words-emotional-regulation-post/"}},{id:"post-worthy-words",title:"Worthy words?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/words-worth-post/"}},{id:"post-narcissist-or-empathetic",title:"Narcissist or Empathetic?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/self-worth-outside-narcissists-post/"}},{id:"post-what-causes-the-sudden-negative-thought-storm",title:"What Causes the Sudden Negative Thought Storm?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/having-stomach-issues-causes-mind-issues-post/"}},{id:"post-what-are-some-good-countries-to-migrate-from-india",title:"What Are Some Good Countries to Migrate from India?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/countries-to-migrate-post/"}},{id:"post-why-did-cain-kill-abel-my-pov",title:"Why did Cain kill Abel? - My POV",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cain-understanding-post/"}},{id:"post-my-bashrc",title:"My bashrc",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/bashrc-post/"}},{id:"post-understanding-two-siblings",title:"Understanding Two Siblings",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/not-pretty-behaviour/"}},{id:"post-the-future-of-jobs-in-the-ai-era-who-39-s-safe-who-39-s-at-risk",title:"The Future of Jobs in the AI Era: Who's Safe, Who's at Risk?...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/new-jobs-with-ai/"}},{id:"post-next-jobs",title:"Next Jobs",description:"My thoughts on next set of Knowledge Jobs",section:"Posts",handler:()=>{window.location.href="/blog/2024/my-thoughts-on-next-jobs/"}},{id:"post-how-to-setup-github-pages",title:"How to setup github pages?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/my-first-post/"}},{id:"news-hoping-to-give-posts-about-words-emotions-sparkles-smile",title:'Hoping to give posts about WORDS, EMOTIONS <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-hoping-to-post-about-llm-and-linux-sparkles-smile-sparkles",title:'Hoping to post about LLM and Linux! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"> <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6C%69%6E%64%61%74%68%61%64%65%75%73@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/lindathadeus","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/lindathadeus","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/lindathadeus","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>