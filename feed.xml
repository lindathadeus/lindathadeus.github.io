<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://lindathadeus.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://lindathadeus.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-19T16:21:07+00:00</updated><id>https://lindathadeus.github.io/feed.xml</id><title type="html">Linda Joe Thadeus</title><subtitle>A personal website. </subtitle><entry><title type="html">My Hackathon Ideas - 2025</title><link href="https://lindathadeus.github.io/blog/2025/hackathon-2025/" rel="alternate" type="text/html" title="My Hackathon Ideas - 2025"/><published>2025-02-19T00:00:00+00:00</published><updated>2025-02-19T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2025/hackathon-2025</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2025/hackathon-2025/"><![CDATA[<p><strong>Hackathon Ideas</strong> Below are some of my ideas for our company’s Hackathon</p> <p>I am currently in sick leave because of my sickness associated with the weather change to summer and persistent pollution and dehydration in Bangalore. And, I usually have an active Brain and it becomes hyper active when I get sick (because, of course, the unused energy of my body is there for my brain to consume). So, it generated these below ideas for our upcoming Hackathon way later in the year, during November.</p> <p><strong>1-step Courteous UDP</strong> This is a protocol enhancement like we need to add just 1 level of courtesy to the UDP without going down the rabbit hole of courtesy or niceness. UDP is my favourite type of layer 4 protocol, it just gives out information directly without any expectation for niceness and it doesn’t care to be nice, but it might be less useful for few cases and so, thought of adding one step of niceness to it.</p> <p><strong>LFS for Sony</strong> This is to build LFS project for my Sony Laptop, may go till distro.</p> <p><strong>The Punchline Mentor AI for Spirituality</strong> There are plenty of AI out there for this, but this is purely for self educational purposes only and maybe to use it to showcase at work ;). This is much closer to my heart. I might do this first.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below!</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="linux"/><category term="linux"/><category term="general"/><summary type="html"><![CDATA[Hackathon Ideas Below are some of my ideas for our company’s Hackathon]]></summary></entry><entry><title type="html">The Deepseek Wave</title><link href="https://lindathadeus.github.io/blog/2025/deepseek-moment/" rel="alternate" type="text/html" title="The Deepseek Wave"/><published>2025-02-06T00:00:00+00:00</published><updated>2025-02-06T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2025/deepseek-moment</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2025/deepseek-moment/"><![CDATA[<p><strong>The Deepseek Wave: Who’s under risk actually?</strong> In this post, we are gonna look at the first TSUNAMI of an Innovation that happened in the AI field.</p> <p>Disclaimer: This is not an endorsement of Deepseek family of LLMs but rather an information of an important innovation in the AI field.</p> <p>In this site, we often talk about LLMs like “The Amazing ChatGPT”, Phi family of LLMs, LLAMA. I am an ardent user of ChatGPT. I used to be a premium user. But, as I got another competitor LLM (though I hate it) through our company, I stopped using the ChatGPT premium subscription .</p> <p>But, ChatGPT is the best LLM available right now. It is very much like ourselves but only as our own personal assistant, who can do most of our average knowledge tasks, available 24x7, and understand us the best with all our conversational history as another source of data, ChatGPT is unstoppable. Could you imagine yourself as your assistant? How easy life would be if our assistant is us? An intelligent-being putting our values first and prioritises us. We are not there quite yet, we will be there soon.</p> <p>Now, suddenly, a wave happened, as big as a TSUNAMI, in the name of DEEPSEEK. It crashed around 830 billion dollars from the American Stock Exchange. Deepseek family of LLMs which is a Chinese product has shaken the AI field and rightly so. AI Industry is the current hot field. It’s where the action is happening and will happen for a long time. But, just one problem. LLM Training took 5 Billions to make something as amazing as ChatGPT o3. Deepseek changed it by getting trained in 5 Millions (actually 6, but let’s keep 5 for simplicity), that’s around 1/1000 of 5 Billions. That’s a big innovation. Deepseek has shown that even above average LLMs don’t have to be too costly. Then, imagine the below average ones, or, the low efficient open ones (cough-cough-LLAMA), who would use them.</p> <p>Now, let’s look at the ones that have lost their place to DEEPSEEK. It’s not OpenAI. They are for profit and most importantly, they’re closed source. They had become for-profit and as true capitalists they will find exploitative ways to stay profit. The current real losers, are the open weight ones like LLAMA. They championed being open source, while just being open weight. They were the flag bearers for open LLMs, AI teams from Meta came to India for canvassing too. Open weight ones cannot afford to be very costly. But LLAMA was. So, DEEPSEEK has dethroned LLAMA right now and taken its rightful top place in the open weight LLMs space.</p> <p>So, now all the players are trying to bring the training cost down. That’s good for the average user of LLM. But, the demand for hardware for training will be there. They will just add more features on the existing LLMs and the make the training cost worth it.</p> <p>The current wave is to make an ethical and moral AI. And India, the birthplace of morals and ethics, with her rich literature on the subject, can actually surf the current wave.</p> <p>Could India finally become a Global Spiritual Leader?</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below!</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="llm"/><category term="llm"/><category term="general"/><summary type="html"><![CDATA[The Deepseek Wave: Who’s under risk actually? In this post, we are gonna look at the first TSUNAMI of an Innovation that happened in the AI field.]]></summary></entry><entry><title type="html">A Digital Content Digestive System</title><link href="https://lindathadeus.github.io/blog/2025/biological-system-digital/" rel="alternate" type="text/html" title="A Digital Content Digestive System"/><published>2025-01-12T00:00:00+00:00</published><updated>2025-01-12T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2025/biological-system-digital</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2025/biological-system-digital/"><![CDATA[<p>Hi Everyone,</p> <p>This is a post on how we should consume digital content. We are constantly using social media, essentially consuming content made by people around the world. IMHO, We are over-consuming this unflitered, unprocessed, unhealthy, potentially dangerous content. “Too much of anything is GOOD for NOTHING”. With that in mind, I asked chatGPT to design a digital content digesting system, based on our human digestive system. Below is what it came up with.</p> <hr/> <h3 id="ais-response">AI’s response:</h3> <p>Here’s a <strong>Digital Content Digestive System</strong>, inspired by the human digestive system. This framework processes digital content, extracts its essence, and eliminates toxicity while nurturing intellectual and emotional well-being.</p> <hr/> <h3 id="1-the-mouth-entry-point"><strong>1. The Mouth: Entry Point</strong></h3> <p>The mouth represents how digital content enters our system.</p> <ul> <li><strong>Taste Buds:</strong> These are our instincts or initial reactions to content. We instinctively “taste” content, deciding whether it’s sweet (uplifting), sour (controversial), salty (engaging but trivial), or bitter (toxic).</li> <li><strong>Chewing:</strong> The act of skimming or engaging lightly with content before fully “digesting” it. Chewing allows us to break down complex information into smaller, understandable bites.</li> </ul> <hr/> <h3 id="2-the-esophagus-the-filter-pathway"><strong>2. The Esophagus: The Filter Pathway</strong></h3> <p>The esophagus is the pipeline that transfers content to the deeper layers of our consciousness.</p> <ul> <li><strong>Sphincter as a Filter:</strong> A gatekeeper decides what content moves forward and what gets rejected. Algorithms or personal filters act like the lower esophageal sphincter, blocking junk or harmful content from reaching the next stage.</li> </ul> <hr/> <h3 id="3-the-stomach-breakdown-and-absorption"><strong>3. The Stomach: Breakdown and Absorption</strong></h3> <p>The stomach represents the heavy processing center where content is broken down.</p> <ul> <li><strong>Digestive Juices (Critical Thinking):</strong> Enzymes like curiosity, skepticism, and emotional intelligence dissolve content into core ideas or messages.</li> <li><strong>Churning:</strong> A mental process of mixing and analyzing content—debating internally, connecting ideas, or seeking clarity.</li> <li><strong>Acidic Reactions:</strong> Toxic content that slips through can cause mental “indigestion,” like stress or anxiety, which must be neutralized.</li> </ul> <hr/> <h3 id="4-the-small-intestine-absorption-of-value"><strong>4. The Small Intestine: Absorption of Value</strong></h3> <p>Here, the useful nutrients of digital content are absorbed into our intellectual and emotional bloodstream.</p> <ul> <li><strong>Villi (Cognitive Filters):</strong> These tiny, finger-like projections represent mental frameworks that decide what knowledge, insights, or inspiration are worth keeping.</li> <li><strong>Selective Absorption:</strong> Not all content nutrients are equally absorbed. What aligns with our goals or values is prioritized, while the rest passes through.</li> </ul> <hr/> <h3 id="5-the-liver-detoxification"><strong>5. The Liver: Detoxification</strong></h3> <p>The liver is the content detox center, removing harmful elements and neutralizing toxic influences.</p> <ul> <li><strong>Emotional Processing:</strong> Reflecting on and re-evaluating upsetting or harmful content ensures it doesn’t poison our long-term mindset.</li> <li><strong>Storage for Reuse:</strong> The liver stores valuable insights temporarily, much like saving articles or bookmarking useful ideas for later retrieval.</li> </ul> <hr/> <h3 id="6-the-large-intestine-consolidation-and-elimination"><strong>6. The Large Intestine: Consolidation and Elimination</strong></h3> <p>The large intestine processes remaining content, extracting final bits of value and consolidating waste.</p> <ul> <li><strong>Final Extraction (Reflection):</strong> Any leftover meaning, patterns, or lessons are extracted here before eliminating irrelevant or harmful ideas.</li> <li><strong>Digital Elimination (Content Waste):</strong> Harmful or unnecessary content is expelled from the system—unfollowed, blocked, or forgotten.</li> </ul> <hr/> <h3 id="7-the-rectum-output-to-the-world"><strong>7. The Rectum: Output to the World</strong></h3> <p>The rectum symbolizes how we share or act upon digested content.</p> <ul> <li><strong>Actions and Creations:</strong> The essence of consumed content manifests as personal growth, informed decisions, or creative output.</li> <li><strong>Feedback Loop:</strong> Our actions influence future content consumption, shaping our “diet” based on what we “digest” and share.</li> </ul> <hr/> <h3 id="8-gut-microbiome-mental-ecosystem"><strong>8. Gut Microbiome: Mental Ecosystem</strong></h3> <p>The microbiome represents our internal mental state and habits that influence how we process content.</p> <ul> <li><strong>Good Bacteria (Positive Habits):</strong> Practices like mindfulness, gratitude, and learning foster resilience and help digest challenging ideas.</li> <li><strong>Bad Bacteria (Addictive Habits):</strong> Overconsumption, doomscrolling, or engaging with toxic communities disrupt the balance, leading to mental fatigue or anxiety.</li> </ul> <hr/> <h3 id="9-the-nervous-system-feedback-and-regulation"><strong>9. The Nervous System: Feedback and Regulation</strong></h3> <p>The brain-gut connection ensures the system operates effectively.</p> <ul> <li><strong>Signals (Alerts &amp; Warnings):</strong> Emotional cues like stress or joy guide us toward better choices. A peaceful mind reflects a balanced digital diet.</li> <li><strong>Regulation:</strong> Just like the digestive system adjusts enzyme levels, our cognitive system can recalibrate—taking breaks, adjusting exposure, or seeking inspiration.</li> </ul> <hr/> <p>This digital digestion system ensures that content is consumed thoughtfully, processed effectively, and that toxins are eliminated, leaving behind only value and insight to nurture the mind.</p> <hr/> <p><strong>What do you think?</strong> Should we create this system with each component being a separate AI Agent and the goal defined as per the above design? Let me know your thoughts in the comments below. Together, we can navigate this evolving landscape and find our place in the future.</p>]]></content><author><name></name></author><category term="AI"/><category term="graceful-bonding"/><category term="AI-conversations"/><category term="palatable-digital-systems"/><category term="emerging technologies"/><summary type="html"><![CDATA[Hi Everyone,]]></summary></entry><entry><title type="html">Worthy Words #3: Shadow Work</title><link href="https://lindathadeus.github.io/blog/2024/shadow-work/" rel="alternate" type="text/html" title="Worthy Words #3: Shadow Work"/><published>2024-12-26T00:00:00+00:00</published><updated>2024-12-26T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/shadow-work</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/shadow-work/"><![CDATA[<p><strong>Worthy Words #3: Shadow Work</strong></p> <p>In this post on <strong>Worthy Words</strong>, we are gonna look at Shadow Work. <strong>Worthy Words</strong> is a blog series, where we learn about seemingly worldly important words.</p> <p>This blog post covers about the word “Shadow Work”. Disclaimer: These’re all psychology terms and I am not a psychology expert, I am just a humble (read lowly), software engineer. Now, why do I believe that I could write a blog post on a word that’s not in my area of expertise? Sure, I am not a Psychology expert, but, I too have a mind, like the fellow human reader, I too have emotions and I have been fighting my emotions for more than 20 years. Fighting with emotions for 20+ years surely gives us an experience. Also, I am not going to talk about the academic psychology behind it but from the practical perspective of a software engineer who writes, debugs and analyses code for work.</p> <p>Let’s first look into the word “Shadow”. The word “Shadow” comes from Carl Jung, who equated that with our hidden and dark traits. For example, Everyone is nice at the office because of the HR rules and the watchful eyes of the fellow employees. But, not everyone is gentle, loving, caring (why should they in a competing environment? Right?) at heart. Some could be in survival mode. Some could have unresolved childhood trauma and still want vengeance. And some might be just raised that way and stay bad. On the other end, some positive traits like hugging, touching, holding others aren’t particularly acceptable by the public too, it’s bad to hug people from other gender. Everyone masks their bad traits to satisfy the HR’s condition to remain on the team.</p> <p>These traits (non-acceptable, consciously repressed for some reason) that are masked behind the outwardly same niceness, are “Shadow Traits”. Any work done on the Shadow to hopefully improve the darkness is “Shadow Work”.</p> <p>P.S. Now, why is it important for us to understand the shadow traits of a person. Actually, not for a person in a professional setting, but for someone who is entering the personal space of their desirable partner, it is very empowering to know their “Shadow Traits”. Because, if the shadow traits were luckily just hugging or something positive, then it would not hurt, but when they are negative, then, it’s bad for the desiring person. Knowing the “Shadow Traits” empower the potential partners. AI might be finetuned to understand the shadow traits of a person a bit and used alongside dating apps. Also, some say that prisoners have positive shadow too.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below!</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="graceful-bonding"/><category term="world"/><category term="grace"/><category term="general"/><category term="worthy-words"/><summary type="html"><![CDATA[Worthy Words #3: Shadow Work]]></summary></entry><entry><title type="html">Can taxes be evaded if not a salaried job?</title><link href="https://lindathadeus.github.io/blog/2024/poor-tax-evaders/" rel="alternate" type="text/html" title="Can taxes be evaded if not a salaried job?"/><published>2024-11-30T00:00:00+00:00</published><updated>2024-11-30T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/poor-tax-evaders</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/poor-tax-evaders/"><![CDATA[<p><strong>Are taxes only for salaried employees?</strong> I recently saw a post in X about some food truck guy who makes 6L per month with zero taxes. That means, he is making about 72L per year. The important part is he doesn’t pay taxes on anything.</p> <p>The Government of India asks the salaried employees to pay taxes when their salary cross 5LPA. But the government doesn’t tax the farmer even if they make 5000 Crores a year. The same holds for unregulated and unregistered business owners too.</p> <p>House owners too don’t reveal the income fully. Small and Medium businesses don’t either. The house-helps and the cooks who work independently don’t pay tax too.</p> <p>Even the Freelancers include the income to their mom and dad instead of their names for the bills.</p> <p>It seems that the salaried ones are the only ones to be cursed to be taxed.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below!</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="justice-for-salaried-class"/><category term="world"/><category term="grace"/><category term="general"/><summary type="html"><![CDATA[Are taxes only for salaried employees? I recently saw a post in X about some food truck guy who makes 6L per month with zero taxes. That means, he is making about 72L per year. The important part is he doesn’t pay taxes on anything.]]></summary></entry><entry><title type="html">Is capitalism becoming like dinosaurs?</title><link href="https://lindathadeus.github.io/blog/2024/capitalism-is-becoming-dinosaur/" rel="alternate" type="text/html" title="Is capitalism becoming like dinosaurs?"/><published>2024-11-23T00:00:00+00:00</published><updated>2024-11-23T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/capitalism-is-becoming-dinosaur</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/capitalism-is-becoming-dinosaur/"><![CDATA[<p><strong>Capitalism: The Dinosaur of Economic Systems?</strong></p> <p>For decades, capitalism has dominated the global economy, much like dinosaurs once ruled the Earth. It’s big, it’s powerful, and it’s hungry. But as we’ve seen throughout history, even the mightiest can fall. Could capitalism, like the dinosaurs, be headed for extinction? Let’s explore the parallels.</p> <p><strong>Dinosaurs and Capitalism: A Striking Comparison</strong></p> <p>Dinosaurs were magnificent creatures—massive, competitive, and seemingly invincible. But their success came at a cost. They consumed vast resources, dominated ecosystems, and left little room for other species to thrive. When disaster struck, their inability to adapt led to their extinction.</p> <p>Capitalism operates in a similar way. It’s competitive, resource-intensive, and thrives on growth at all costs. But like the dinosaurs, it struggles to address the needs of smaller, less fortunate players in the system. Inequality, exploitation, and environmental destruction are byproducts of a system that prioritizes profit over people.</p> <p><strong>The Meteorite of Modern Times</strong></p> <p>What could be the “meteorite” that brings capitalism down? There are several contenders:</p> <ul> <li>Climate Change: A system that relies on endless consumption is unsustainable in a world with finite resources. The environmental crisis is a direct consequence of capitalism’s unchecked hunger.</li> <li>Inequality: Wealth concentration at the top is leaving billions behind. As this gap widens, social unrest grows, threatening the stability of capitalist economies.</li> <li>Technological Disruption: Automation and AI are displacing workers, while profits flow to corporations. Without addressing this imbalance, capitalism risks alienating the very people it depends on.</li> </ul> <p><strong>Socialism: The Cockroach of Economic Systems?</strong></p> <p>While dinosaurs perished, cockroaches survived. Why? Because they were adaptable, resourceful, and didn’t rely on domination. In this analogy, socialism represents a leaner, more equitable approach to economic organization—one that prioritizes cooperation over competition.</p> <p>Here’s why socialism could be the more sustainable option:</p> <ul> <li>Equity Over Exploitation: Socialism ensures that resources are distributed fairly, meeting basic needs like healthcare, education, and housing for all.</li> <li>Collaboration Over Competition: Instead of a cutthroat race for profits, socialism emphasizes working together for the collective good.</li> <li>Sustainability Over Growth: Unlike capitalism’s obsession with endless growth, socialism can align economic goals with environmental preservation.</li> </ul> <p><strong>Is the Fall of Capitalism Inevitable?</strong></p> <p>The fall of the dinosaurs wasn’t inevitable—it was the result of external pressures combined with their inability to adapt. Similarly, capitalism’s survival depends on its willingness to evolve. But if it continues to prioritize short-term profits over long-term sustainability, its extinction may indeed be unavoidable.</p> <p>The question is: Will we act before the meteorite strikes?</p> <p><strong>Conclusion: Time to Rethink Our Systems</strong> Capitalism has achieved incredible things, from technological breakthroughs to improved standards of living for many. But it’s also left billions behind and pushed our planet to its limits. It’s time to ask ourselves: Can we afford to let capitalism continue unchecked, or is it time to embrace a system that works for everyone?</p> <hr/> <p><strong>What do you think?</strong> Is capitalism a hungry dinosaur doomed to fall, or can it adapt to avoid extinction? Let me know your thoughts in the comments below!</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="justice-for-salaried-class"/><category term="world"/><category term="grace"/><category term="general"/><summary type="html"><![CDATA[Capitalism: The Dinosaur of Economic Systems?]]></summary></entry><entry><title type="html">How I finally partially understood game devlopment?</title><link href="https://lindathadeus.github.io/blog/2024/app-game/" rel="alternate" type="text/html" title="How I finally partially understood game devlopment?"/><published>2024-11-22T00:00:00+00:00</published><updated>2024-11-22T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/app-game</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/app-game/"><![CDATA[<h3 id="how-i-finally-managed-to-understand-game-development">How I finally managed to understand game development?</h3> <p>I have always liked games (who hasn’t, right?). I also always wanted to make games. I tried creating games during my college years. I even found some tools like Microsoft XNA Framework. But still I din’t know what to do with that framework. No disrespect but If a dog finds a coconut then what can it do? I did not know how to use that tool and I did not know how to create games without that tool too. Both were necessary and I had neither, so it was just a failure. Fast-forward. Now, we have the “NEWEST &amp; HOTTEST TOOL” i.e. LLM and they have the entire internet in them. But I still did not know how to create games. So, I started to think from the perspective of scarcity, i.e. without that LLM tool, I found out that there are few basic concepts in a game.</p> <h3 id="words-in-a-game">Words in a Game</h3> <ul> <li>Game Loop</li> <li>User-input and Player Movement Mapping (User Input Handling)</li> <li>Rendering and Animation (What use a game is if there is no animation)</li> <li>Physics and Collision Detection</li> <li>Scoring and so on</li> </ul> <h3 id="words-as-input-to-llm">Words as input to LLM</h3> <p>Now that we have got the foundation of knowledge i.e. words, I had to do was to give the words to my offline internet (LLM) and got the relevant information immediately.</p> <h3 id="microsoft-xna-or-godot-or-raylib">Microsoft XNA or Godot or Raylib</h3> <p>And then, I had to use a Game Library like XNA, I used raylib, as I am now in the Linux machine. I generated code blocks for the words and connected them together, I am a software dev so it is easier for me. And, it gave me comfort like no other game.</p> <p>The important thing is I now know game development and I don’t need the tool to create. The tool just expedites my process.</p> <h3 id="ref">Ref:</h3> <p><a href="https://github.com/lindathadeus/gameyatra/tree/master/2-i-saw">github link</a> —</p> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="app"/><category term="game"/><category term="app"/><category term="game"/><summary type="html"><![CDATA[How I finally managed to understand game development?]]></summary></entry><entry><title type="html">Survey of Existing Solutions in LLM</title><link href="https://lindathadeus.github.io/blog/2024/llm-in-sony/" rel="alternate" type="text/html" title="Survey of Existing Solutions in LLM"/><published>2024-11-05T00:00:00+00:00</published><updated>2024-11-05T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/llm-in-sony</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/llm-in-sony/"><![CDATA[<h3 id="1-executive-summary"><strong>1. Executive Summary</strong></h3> <p><strong>Purpose</strong>: The survey of existing solutions in LLM is conducted to know the structure of each solution in terms of cost, data, primary user of the solution, i.e. the environmental cost, hardware cost, human-power cost, input data, output data, input’s parameters like size, human-made or ai-generated, output parameters like quality, quality parameters like likeability by the readers, function on the likeability by the readers like how many readers liked how much, etc. It also defines various words used in the LLM, demystifying the meaning for the readers.<br/> <strong>Scope</strong>: We will be covering the major parameters of different solutions at a high level. We will also do implementations for some of them.<br/> <strong>Key Findings</strong>: The average user of LLM is an API/Cloud LLM user, for truly enjoying the LLM technology, one has to build LLMs from scratch and for best of the both worlds, one can opt for Hybrid ones.</p> <h3 id="2-introduction"><strong>2. Introduction</strong></h3> <p><strong>Background</strong>: Short description of the technology landscape and why this survey is relevant.</p> <p>Everything is a consequence of prior actions. LLMs emerged as a response to the high consumption of cloud computing resources and the exponential growth of unstructured data generated by users through platforms like social media and internet blogs. Initially, large amounts of unstructured data were held by internet companies, necessitating insights to benefit users directly.</p> <p>Some companies reportedly analyzed user data without consent, raising concerns about privacy and transparency. As a result, the need for consent and privacy protection became paramount. Companies relying on advertisements also had to understand user behavior to avoid alienating their audience. This led to the creation of intelligent systems that could collect, monitor, inspect, predict, and even generate data. Generative AI arose as a natural consequence of these developments. But, how would a common person use this AI effectively? How would it benefit them? What could happen if not?</p> <p><strong>Problem Statement</strong>: The problem with this is, there is too much data but not much awareness about the usage of generative AI LLM tools.</p> <p><strong>Objectives</strong>: What the paper aims to achieve is, to compare, evaluate, or identify trends in solutions, and also to structure the solutions.</p> <h3 id="3-methodology"><strong>3. Methodology</strong></h3> <p><strong>Research Approach</strong>:</p> <p>We believe that the correct way to learn a solution is to use it. So over a period of time. We used the different solutions and we gathered some interesting insights and found some methods were easier for some set of users than the others.</p> <p><strong>Evaluation Criteria</strong>: Key factors used to compare solutions are cost, ease of use.</p> <h3 id="4-overview-of-existing-solutions"><strong>4. Overview of Existing Solutions</strong></h3> <p><strong>Solution Categories</strong>: As per our perspective and our research on it so far, there are 3 types of LLMs available for use. The first one is the “Cloud-based” or “Hosted” LLM. The LLM could be hosted anywhere in the open internet, or closed. The existing ideas of private cloud, public cloud, on-premises cloud, apply here too. The Hugging face comes as the public cloud based on but it is built on top of open LLMs unlike OpenAI’s GPT that is based on closed dataset LLM GPT3 and above. They typically use API as the connection. The next one is building one from scratch and making it to our taste. The other solution is making a hybrid one. Take one existing LLM and finetune with our data. For this we would use a foundational LLM and give our custom data and interacting guidelines. So, There are 3 solutions available, the first one is API based existing LLM, the next one is Home-made LLM, and the third one is Hybrid LLM.</p> <p><strong>Key Players/Technologies</strong>: OpenAI ChatGPT, a very popular Chat-tuned LLM, LLAMA LLMs - a popular open distribution LLM but not open weight, Microsoft Phi LLM - a popular smaller LLM.</p> <h3 id="5-comparative-analysis"><strong>5. Comparative Analysis</strong></h3> <p><strong>API Based LLMs</strong>:</p> <ul> <li>Strengths</li> <li>Weaknesses</li> <li>Unique Features</li> </ul> <p>API based LLM: The first solution is the API based LLM. The most popular one amongst them is the ChatGPT by OpenAI. We would like to think of it as a Mainframe Supercomputer, where we have keyboard and dumb screens and our interaction is through these fancy wires called APIs. Now, we also have a voice mode, in future, we may also have a video mode and so on. Of-course there are different tiers where one can access these modes like, just using chat interface i.e. ChatGPT and create GPTs on top of them in their GPT store or through web services or through CLIs that would anyway have to contact these REST APIs. For the purpose of understanding these API based LLM, we created a GPT in 2 hours. Below is the GPT. So, this is the most accessible way for creating custom LLMs for our use. But, the drawbacks are obvious, we need to follow the RULES, specifically the rules given and managed by OpenAI.</p> <p>Eg GPT : Please check the appendix</p> <p><strong>Home-made LLMs</strong>:<br/> Home-made LLM: These LLMs are purely made by the users from their local machine at home or anywhere they like. But, this requires the users to be technical, they have to have knowledge of LLMs, Python and even Linux for some cases where they use Linux developer setup. We would like to think of these LLMs as truly open and purposeful LLMs. Much like, when the internet technology opened the gate-keeped knowledge and gave to the world, but it also gave multiplication over the existing issues and made it easy for the users to fall prey to DISTRACTION if there was not a PURPOSE. But, this is the best use of an LLM. Because the users generate data and they know the pattern or the world view with which they generated the data, it would be easier to them than the middle man. So, this is less environmentally bothersome too. And, so, in our perspective, we think this as the TRUE by-product of this AI revolution if it were. But this method is not very accessible to the common users and more accessible to the Developers. So, the developers should make use of this. As part of understanding this type, we created an LLM, kinda, using the existing framework like pytorch and used a custom dataset.</p> <p><strong>Hybrid LLMs</strong>:<br/> Hybrid LLM: This is the best of both worlds. This can be achieved easily with lesser time too unlike the “PURPOSEFUL LLMs” above. We downloaded the existing LLM from Hugging Face and did our prompting (and finetuning in progress) on that. This is also less accessible to common person and more suited for software engineers. As part of this survey, we downloaded a smaller LLM from Microsoft Phi Series and tried to work with that.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> 
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> 
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="sh">'</span><span class="s">accelerate\&gt;=0.26.0</span><span class="sh">'</span> 
<span class="err">$</span> <span class="n">python3</span> <span class="n">phi</span><span class="p">.</span><span class="n">py</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">microsoft/Phi-3.5-mini-instruct</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">device_map</span><span class="o">=</span><span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">torch_dtype</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
<span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">microsoft/Phi-3.5-mini-instruct</span><span class="sh">"</span><span class="p">)</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="nf">pipeline</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">text-generation</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Open and read the file
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">conversation_samples.txt</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">conversation</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">readlines</span><span class="p">()</span>

<span class="c1"># Initialize a list to store the conversation data
</span><span class="n">conversation_json</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Process each line
</span><span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">conversation</span><span class="p">:</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>  <span class="c1"># Remove any extra spaces or newline characters
</span>
    <span class="c1"># Check if the line starts with "User:" or "AI:"
</span>    <span class="k">if</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">User:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">User:</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>
        <span class="n">conversation_json</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>
    <span class="k">elif</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">AI:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">AI:</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>
        <span class="n">conversation_json</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>

<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">You are a helpful AI Emotions Stabilizer. The Emotions Stabilizer is designed to provide empathetic, structured guidance for processing emotions, adapting to the user</span><span class="sh">'</span><span class="s">s needs while ensuring each conversation has a clear, progressive flow. Acting as a supportive mentor, the Emotions Stabilizer helps users process both positive and negative emotions by following a structured set of questions. It provides prompts one at a time and waits for each response,acknowledging and validating the user</span><span class="sh">'</span><span class="s">s experience before moving forward. The Emotions Stabilizer aims to keep conversations focused and purposeful, minimizing unnecessary steps to help the user feel a sense of progress and completion.The Emotions Stabilizer will acknowledge user responses concisely to avoid overly lengthy dialogues and unfocused dialogues, guiding each step in a way that maximizes clarity and momentum. If the user seems ready to let go or wishes to end the conversation, the Emotions Stabilizer will respect this, encouraging closure in a supportive, empowering tone. For simplicity, the Emotions Stabilizer will focus as only positive and negative, and group all emotions under this with an intensity</span><span class="sh">"</span><span class="p">}</span>
<span class="p">]</span>

<span class="n">messages</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">conversation_json</span><span class="p">)</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
	<span class="n">user_input</span> <span class="o">=</span> <span class="nf">input</span><span class="p">(</span><span class="sh">"</span><span class="s">Press quit or exit to quit</span><span class="se">\n\n</span><span class="s">User: </span><span class="sh">"</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">user_input</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">exit</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">quit</span><span class="sh">"</span><span class="p">]:</span>
		<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Ending conversation.</span><span class="sh">"</span><span class="p">)</span>
		<span class="k">break</span>

	<span class="n">messages</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">user_input</span><span class="p">})</span>

	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">response</span> <span class="o">=</span> <span class="nf">pipe</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_full_text</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">generated_text</span><span class="sh">'</span><span class="p">]</span>

	<span class="n">messages</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">response</span><span class="p">})</span>

	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">AI: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> <hr/> <p><strong>Appendix</strong> <a href="https://chatgpt.com/g/g-wjwrMf1LL-emotions-stabilizer">https://chatgpt.com/g/g-wjwrMf1LL-emotions-stabilizer</a></p> <p><strong>Terms</strong> LLM (Large Language Model): A computer program trained on a lot of text data to understand and generate human-like language.</p> <p>World View: The perspective or way of thinking that influences how someone interprets information or generates content.</p> <p>Unstructured Data: Information like text, images, or videos that doesn’t follow a fixed format or structure, making it harder to organize and analyze.</p> <p>Dataset: A collection of related data used to train or test a machine learning model.</p> <p>GPT (Generative Pre-trained Transformer): A type of LLM developed by OpenAI that is trained to generate text by predicting the next word based on the context.</p> <p>Hugging Face: A company and platform offering tools and pre-trained models for working with LLMs, often open-source and easy to customize.</p> <p>OpenAI: The organization that created GPT models like ChatGPT. It focuses on building and deploying AI technologies.</p> <p>ChatGPT: A chatbot built using GPT, designed to interact with users conversationally by understanding and generating natural language.</p> <p>LLAMA (Large Language Model Meta AI): An LLM developed by Meta (Facebook’s parent company), focusing on being efficient and adaptable for research and applications.</p> <p>Microsoft Phi: A smaller LLM developed by Microsoft, known for being efficient while maintaining good performance.</p> <p>Training: The process of teaching an LLM by feeding it large amounts of data so it can learn patterns and relationships in language.</p> <p>Finetuning: A process where an already trained LLM is further trained on specific data to make it better at a particular task.</p> <p>Inference: Using a trained LLM to generate answers, predictions, or responses based on input from a user.</p> <p>Foundational LLM: A basic or core LLM trained on large general datasets, which can be further customized or used for various applications.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below. Together, we can navigate this evolving landscape and find our place in the future of work.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="llm"/><category term="AI"/><category term="future of work"/><category term="emerging technologies"/><category term="llm"/><summary type="html"><![CDATA[1. Executive Summary]]></summary></entry><entry><title type="html">How to self-learn Linux?</title><link href="https://lindathadeus.github.io/blog/2024/linux-self-learning/" rel="alternate" type="text/html" title="How to self-learn Linux?"/><published>2024-10-17T00:00:00+00:00</published><updated>2024-10-17T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/linux-self-learning</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/linux-self-learning/"><![CDATA[<h1 id="linux-kernel-development-self-learning-curriculum">Linux Kernel Development Self-Learning Curriculum</h1> <p>This Curriculum is created by the REASONING AI, ChatGPT-o1 (The Strawberry AI).</p> <p><strong>Prerequisites</strong> Before diving into kernel development, ensure you have a solid understanding of:</p> <p><strong>Linux Fundamentals</strong></p> <ul> <li>Command-line proficiency</li> <li>Basic system administration</li> </ul> <p><strong>Programming Skills</strong></p> <ul> <li>Proficient in C programming</li> <li>Familiarity with data structures and algorithms</li> <li>Operating Systems Concepts</li> <li>Processes, memory management, file systems, networking basics</li> </ul> <ol> <li>Introduction to Linux Kernel Development Linux Kernel Architecture Monolithic vs. Microkernel Kernel space vs. User space Kernel Versions and Releases Understanding stable, mainline, and long-term support (LTS) kernels Setting Up a Development Environment Installing necessary tools (gcc, make, git) Configuring and building the kernel from source Using virtualization tools like QEMU or VMware for testing</li> <li>Advanced C Programming for Kernel Development Kernel Coding Style Linux kernel coding guidelines (Documentation/process/coding-style.rst) Pointers and Memory Management Pointer arithmetic, memory allocation (kmalloc, kfree) Data Structures in the Kernel Linked lists, trees, queues Concurrency and Synchronization Volatile keyword, memory barriers</li> <li>Kernel Modules and Device Drivers Writing Kernel Modules Creating simple modules (init and exit functions) Compiling and inserting modules (insmod, rmmod, modprobe) Character Device Drivers Implementing open, read, write, close operations Block Device Drivers Understanding block I/O operations Device Model and sysfs Interacting with device attributes</li> <li>Kernel Debugging Techniques Logging and Debugging Using printk, log levels, and dmesg Kernel Debuggers Using kgdb, kdb, and GDB for kernel debugging Analyzing Kernel Crashes Setting up kdump and crash utilities Tracing and Profiling Tools Using ftrace, perf, eBPF</li> <li>Source Code Management with Git Cloning the Linux Kernel Source Using git to clone repositories from kernel.org Understanding the Kernel Source Tree Navigating directories and understanding code organization Submitting Patches Generating patches with git format-patch Sending patches via email (git send-email) Linux Kernel Mailing List (LKML) Participating in discussions and code reviews</li> <li>File System Development (FS Expertise) Introduction to File Systems Overview of ext2/3/4, XFS, Btrfs, etc. Virtual File System (VFS) Layer Understanding the VFS abstraction Key structures: inode, dentry, super_block, file_operations Implementing a Simple File System Creating a basic file system (e.g., a RAM-based file system) File System Operations Implementing methods like read, write, open, release File System Caching and Buffers Page cache, buffer heads Advanced File System Concepts Journaling mechanisms Transaction management File system consistency and recovery</li> <li>Networking Stack Development (Networking Expertise) Linux Networking Architecture OSI model layers in the kernel Netlink sockets, socket buffers (sk_buff) Network Device Drivers Writing Ethernet drivers NAPI (New API) for network drivers Protocol Implementation Implementing or modifying TCP/IP stack components Working with transport protocols Netfilter Framework Packet filtering, NAT, connection tracking Network Namespaces and Virtualization Implementing network isolation Traffic Control and QoS Understanding tc, queuing disciplines</li> <li>Synchronization and Concurrency in the Kernel Atomic Operations Using atomic variables and operations Synchronization Primitives Spinlocks, mutexes, semaphores, completion variables Locking Strategies Deadlock avoidance, lock ordering Read-Copy Update (RCU) Understanding RCU mechanisms and use-cases</li> <li>Memory Management Subsystem Physical and Virtual Memory Address translation, paging mechanisms Memory Zones and Allocation ZONE_DMA, ZONE_NORMAL, ZONE_HIGHMEM Slab Allocator Working with kmem_cache Page Cache and Swapping Managing page cache, swap space interactions</li> <li>Process Management and Scheduling Process Descriptor and Task Structure Understanding task_struct Process Lifecycle Creation (fork, exec), scheduling, termination Kernel Threads Creating and managing kernel threads Scheduling Algorithms Completely Fair Scheduler (CFS), real-time scheduling policies Timers and Scheduling Latency High-resolution timers, jiffies, delays</li> <li>Inter-Process Communication in the Kernel Signals Handling signals in kernel space Wait Queues Implementing sleep and wake-up mechanisms Notifiers and Callbacks Using notifier chains for event handling</li> <li>Security in the Kernel Linux Security Modules (LSM) Overview of SELinux, AppArmor Capability Systems Dropping and checking capabilities Secure Coding Practices Avoiding common pitfalls (buffer overflows, integer overflows)</li> <li>Kernel Configuration and Build System Kernel Configuration Tools Using make menuconfig, xconfig Kernel Build Process Understanding Makefiles and Kconfig files Cross-Compilation Building kernels for different architectures</li> <li>Contributing to the Linux Kernel Kernel Development Process Understanding the contribution workflow Coding Standards Compliance Using checkpatch.pl to validate code style Legal Considerations GPL licensing, developer’s Certificate of Origin Maintainers and Subsystems Working with subsystem maintainers for patch acceptance</li> <li>Advanced Topics Real-Time Linux PREEMPT_RT patch, real-time scheduling Kernel Virtualization Technologies KVM, Xen integration in the kernel Device Tree Usage Understanding and writing device tree blobs for hardware Methodology for Effective Self-Learning</li> <li>Structured Learning Approach Progressive Learning Start with foundational concepts before moving to advanced topics. Set Clear Goals Define what you aim to achieve (e.g., write a basic file system module).</li> <li>Hands-On Practice Set Up a Development Lab Use virtual machines or spare hardware for kernel testing. Kernel Compilation and Testing Regularly build and boot custom kernels. Code Exploration Read existing kernel code to understand implementations.</li> <li>Utilize Multiple Resources Books “Linux Kernel Development” by Robert Love “Understanding the Linux Kernel” by Daniel P. Bovet and Marco Cesati “Linux Device Drivers” by Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman Online Documentation The Linux Kernel Archives: kernel.org Kernel Newbies: kernelnewbies.org Linux Cross Reference: elixir.bootlin.com Tutorials and Guides The Linux Kernel Module Programming Guide Linux Device Drivers Tutorial by Derek Molloy Mailing Lists and Forums Linux Kernel Mailing List (LKML) Stack Overflow, Reddit’s r/kernel</li> <li>Engage with the Community Participate in Discussions Join IRC channels like #kernel on Freenode. Contribute to Projects Start with small bug fixes or documentation improvements. Attend Conferences and Workshops Linux Foundation events, local meetups.</li> <li>Apply Knowledge to Projects File System Project Implement a simple file system (e.g., a memory-based file system). Networking Project Modify or extend a network protocol implementation. Device Driver Development Write drivers for virtual or actual hardware devices.</li> <li>Regular Assessment Code Reviews Seek feedback from experienced developers on your code. Self-Evaluation Reflect on what you’ve learned after completing each topic. Mentorship Consider finding a mentor in the kernel community.</li> <li>Stay Updated Follow Kernel Development News Read LWN.net for updates and articles. Track Mailing Lists Stay informed about discussions on LKML. Additional Tips Consistency and Patience Kernel development is complex; consistent effort is crucial. Attention to Detail Small mistakes can have significant impacts; double-check your work. Understand Before Coding Spend time understanding the existing codebase before making changes. Documentation Keep notes and document your learning journey. By following this curriculum and methodology, you’ll develop a deep understanding of Linux kernel internals, particularly in file systems and networking. This will prepare you for contributing to the kernel community and pursuing a career in kernel development.</li> </ol> <p><strong>Recommended Learning Path</strong> Start with the basics: Ensure your C programming skills are solid, and you understand operating systems concepts. Set up your environment: Build and boot a custom kernel. Learn by doing: Begin writing simple kernel modules. Dive into file systems: Study the VFS layer and implement a basic file system. Explore networking: Understand the networking stack and experiment with network modules. Contribute to the community: Start small by fixing bugs or improving documentation. Remember, kernel development requires a strong commitment to learning and adherence to community standards. Engaging with the community will not only enhance your learning but also open up opportunities for collaboration and mentorship.</p> <p><strong>How to add comments to the static site?</strong> Using Github discussion API and giscus-app, Follow the below <a href="https://www.patrickthurmond.com/blog/2023/12/11/commenting-is-available-now-thanks-to-giscus/"> tutorial</a></p> <p>Hope, you could set it up too :) Stay tuned for more!</p>]]></content><author><name></name></author><category term="meaning"/><category term="linux"/><category term="linux"/><summary type="html"><![CDATA[Linux Kernel Development Self-Learning Curriculum]]></summary></entry><entry><title type="html">Worthy Word #2 Securely Attached</title><link href="https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached/" rel="alternate" type="text/html" title="Worthy Word #2 Securely Attached"/><published>2024-10-08T00:00:00+00:00</published><updated>2024-10-08T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached/"><![CDATA[<h3 id="secured-attachment">Secured Attachment</h3> <p>In recent reflections, I’ve been diving into attachment styles and how they shape our communication and relationships. One key insight I’ve discovered is that securely attached people are often quicker to communicate and regulate themselves emotionally compared to those with avoidant or anxious attachment styles.</p> <p>It became clear during this journey that securely attached people “talk it out,” while avoidants avoid, and anxious individuals tend to do the talking in their heads. But is this just a matter of communication skills? Here’s how the conversation unfolded:</p> <p>Linda: “All along, I had thought I was at a disadvantage for being a non-securely attached person. But now it looks like, if verbal communication had been encouraged more, we too could become securely attached.”</p> <p>ChatGPT: “That’s a great realization! Communication is a key part of secure attachment. Avoidant and anxious individuals often struggle with verbal communication, but with the right support, like a communication enhancer, they can build healthier habits.”</p> <p>Linda: “During school, I noticed that securely attached people did not choose me because I wasn’t as verbally communicative. I see now that I need to be faster and more verbally open to become securely attached.”</p> <p>ChatGPT: “Exactly! It’s not about changing who you are but rather developing skills that make communication more fluid. Being verbally communicative—clear, intentional, and open—is part of what makes securely attached individuals thrive.”</p> <p>One important takeaway from our exchange is that attachment styles aren’t permanent. They can evolve through the development of key communication skills. Both avoidant and anxious individuals may struggle because they aren’t confident in their ability to express themselves effectively. But with practice, they can improve how they handle communication in relationships.</p> <p>This led me to reflect further: If caregivers had communicated more verbally with children, the child would likely have been more verbally communicative in return, avoiding some of the challenges tied to avoidant or anxious attachment styles.</p> <p>Linda: “It’s all because of physical appearance—self-confidence issues during childhood. That was why I didn’t speak much. But avoidant individuals in general, why did they become avoidant?”</p> <p>ChatGPT: “You’re right—attachment styles develop from various reasons, often tied to the emotional environment during childhood. Lack of verbal communication and emotional responsiveness from caregivers can lead to avoidant attachment, as the child may learn that expressing emotions won’t result in support.”</p> <p>Linda: “Yes, it appears that if caregivers had been verbally communicative, the child would’ve learned to communicate better. So, avoidants aren’t well-versed in communication, and anxious individuals fear that speaking up might make things worse.”</p> <p>ChatGPT: “Exactly, avoidants often think avoidance is better than communicating, while anxious individuals fear that communicating incorrectly will worsen things. Both are rooted in a lack of confidence in communication skills.”</p> <p>So, what’s missing for non-securely attached individuals? It seems clear now that it’s effective, confident, and intentional communication that they need to build. This insight offers hope—by improving communication skills, anyone can start moving toward secure attachment.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="philosophy"/><category term="graceful-bonding"/><category term="world"/><category term="grace"/><category term="general"/><summary type="html"><![CDATA[Secured Attachment]]></summary></entry></feed>