<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://lindathadeus.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://lindathadeus.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-11-18T13:31:39+00:00</updated><id>https://lindathadeus.github.io/feed.xml</id><title type="html">Linda Joe Thadeus</title><subtitle>A personal website. </subtitle><entry><title type="html">Survey of Existing Solutions in LLM</title><link href="https://lindathadeus.github.io/blog/2024/llm-in-sony/" rel="alternate" type="text/html" title="Survey of Existing Solutions in LLM"/><published>2024-11-05T00:00:00+00:00</published><updated>2024-11-05T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/llm-in-sony</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/llm-in-sony/"><![CDATA[<h3 id="1-executive-summary"><strong>1. Executive Summary</strong></h3> <p><strong>Purpose</strong>: The survey of existing solutions in LLM is conducted to know the structure of each solution in terms of cost of the solution, environmental cost, hardware cost, human-power cost, input data, output data, input’s parameters like size, human-made or ai-generated, output parameters like quality, quality parameters like likeability by the readers, function on the likeability by the readers like how many readers liked how much, etc. It also defines various words used in the LLM, demystifying the meaning for the readers.<br/> <strong>Scope</strong>: We will be covering the major parameters of different solutions at a high level. We will also do implementations for some of them.<br/> <strong>Key Findings</strong>: The average user of LLM is an API/Cloud LLM user, for truly enjoying the LLM technology, one has to build LLMs from scratch and for best of the both worlds, one can opt for Hybrid ones.</p> <h3 id="2-introduction"><strong>2. Introduction</strong></h3> <p><strong>Background</strong>: Short description of the technology landscape and why this survey is relevant.</p> <p>Everything, action has a consequence. Also, everything is a consequence of a previous action or actions. LLM was a consequence of high consumption of Cloud Computing Resources that resulted in the High Volume Unstructured Data from the users themselves through the technological innovation that operated on the cloud like social media and internet blogs instead of just the companies that host the computing resources, Some Initial Patterns or Learning Methodology or some rules. Like we had seen earlier, there were humongous amounts of unstructured data available with these internet companies created by the people of the Earth, there was a need to generate insights from the people, so that we can benefit the people directly. So, there came a need to study patterns in their data. Some companies, they say, collected and studied the users’ data without consent. So there comes the need to get consent. Also, these data put forth by the users are out there for another user to get data too, that means, the user needs privacy protection too. So, anyway the large companies that had these bulk of these user-data and some of them relied on advertisements for money, so they had to understand the user’s needs otherwise, the companies feared getting blocked off by the user. So, all these meant there had to be a super data collector, monitor, inspector, predictor that would deal with all the previous problems. The intelligent system had to predict user behavior, they may even have to generate scenarios and more data. AI in the form of generative AI came as a natural consequence. But, how would a common person use this AI effectively? How would it benefit them? What could happen if not?</p> <p><strong>Problem Statement</strong>: The problem with this is, there is too much data but not much awareness about the usage of generative AI LLM tools.</p> <p><strong>Objectives</strong>: What the paper aims to achieve is, to compare, evaluate, or identify trends in solutions, and also to structure the solutions.</p> <h3 id="3-methodology"><strong>3. Methodology</strong></h3> <p><strong>Research Approach</strong>:</p> <p>We believe that the correct way to learn a solution is to use it. So over a period of time. We used the different solutions and we gathered some interesting insights and found some methods were easier for some set of users than the others.</p> <p><strong>Evaluation Criteria</strong>: Key factors used to compare solutions are cost, ease of use.</p> <h3 id="4-overview-of-existing-solutions"><strong>4. Overview of Existing Solutions</strong></h3> <p><strong>Solution Categories</strong>: As per our perspective and our research on it so far, there are 3 types of LLMs available for use. The first one is the “Cloud-based” or “Hosted” LLM. The LLM could be hosted anywhere in the open internet, or closed. The existing ideas of private cloud, public cloud, on-premises cloud, apply here too. The Hugging face comes as the public cloud based on but it is built on top of open LLMs unlike OpenAI’s GPT that is based on closed dataset LLM GPT3 and above. They typically use API as the connection. The next one is building one from scratch and making it to our taste. The other solution is making a hybrid one. Take one existing LLM and finetune with our data. For this we would use a foundational LLM and give our custom data and interacting guidelines. So, There are 3 solutions available, the first one is API based existing LLM, the next one is Home-made LLM, and the third one is Hybrid LLM.</p> <p><strong>Key Players/Technologies</strong>: OpenAI ChatGPT, a very popular Chat-tuned LLM, LLAMA LLMs - a popular open distribution LLM but not open weight, Microsoft Phi LLM - a popular smaller LLM.</p> <h3 id="5-comparative-analysis"><strong>5. Comparative Analysis</strong></h3> <p><strong>API Based LLMs</strong>:</p> <ul> <li>Strengths</li> <li>Weaknesses</li> <li>Unique Features</li> </ul> <p>API based LLM: The first solution is the API based LLM. The most popular one amongst them is the ChatGPT by OpenAI. We would like to think of it as a Mainframe Supercomputer, where we have keyboard and dumb screens and our interaction is through these fancy wires called APIs. Now, we also have a voice mode, in future, we may also have a video mode and so on. Of-course there are different tiers where one can access these modes like, just using chat interface i.e. ChatGPT and create GPTs on top of them in their GPT store or through web services or through CLIs that would anyway have to contact these REST APIs. For the purpose of understanding these API based LLM, we created a GPT in 2 hours. Below is the GPT. So, this is the most accessible way for creating custom LLMs for our use. But, the drawbacks are obvious, we need to follow the RULES, specifically the rules given and managed by OpenAI.</p> <p>Eg GPT : Please check the appendix</p> <p><strong>Home-made LLMs</strong>:<br/> Home-made LLM: These LLMs are purely made by the users from their home. But, this requires the users to be technical, they have to have knowledge of LLMs, Python and even Linux for some cases where they use Linux developer setup.We would like to think of these LLMs as truly open and purposeful LLMs. Much like, when the internet technology was given to the world, it gave multiplication over the existing issues and so it made easy users fall prey to DISTRACTION if there was not a PURPOSE. But, this is the best use of an LLM. Because the users generate data and they themselves know the pattern or the world view with which they generated the data. So, this is less environmentally bothersome too. And, so, in our perspective, we think this as the TRUE by -product of this AI revolution if it were. But this method is not very accessible to the common users and more accessible to the Developers. So, the developers should make use of this. As part of understanding this type, we created an LLM, kinda, using the existing framework like pytorch and used a custom dataset.</p> <p><strong>Hybrid LLMs</strong>:<br/> Hybrid LLM: This is the best of both worlds. This can be achieved easily with lesser time too unlike the “PURPOSEFUL LLMs” above. We downloaded the existing LLM from Hugging Face and did our prompting on that. This is also less accessible to common person and more suited for software engineers. As part of this survey, we downloaded a smaller LLM from Microsoft Phi Series and tried to work with that.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> 
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> 
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="sh">'</span><span class="s">accelerate\&gt;=0.26.0</span><span class="sh">'</span> 
<span class="err">$</span> <span class="n">python3</span> <span class="n">phi</span><span class="p">.</span><span class="n">py</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">microsoft/Phi-3.5-mini-instruct</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">device_map</span><span class="o">=</span><span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">torch_dtype</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
<span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">microsoft/Phi-3.5-mini-instruct</span><span class="sh">"</span><span class="p">)</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="nf">pipeline</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">text-generation</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Open and read the file
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">conversation_samples.txt</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">conversation</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">readlines</span><span class="p">()</span>

<span class="c1"># Initialize a list to store the conversation data
</span><span class="n">conversation_json</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Process each line
</span><span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">conversation</span><span class="p">:</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>  <span class="c1"># Remove any extra spaces or newline characters
</span>
    <span class="c1"># Check if the line starts with "User:" or "AI:"
</span>    <span class="k">if</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">User:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">User:</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>
        <span class="n">conversation_json</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>
    <span class="k">elif</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">AI:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">AI:</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>
        <span class="n">conversation_json</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>

<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">You are a helpful AI Emotions Stabilizer. The Emotions Stabilizer is designed to provide empathetic, structured guidance for processing emotions, adapting to the user</span><span class="sh">'</span><span class="s">s needs while ensuring each conversation has a clear, progressive flow. Acting as a supportive mentor, the Emotions Stabilizer helps users process both positive and negative emotions by following a structured set of questions. It provides prompts one at a time and waits for each response,acknowledging and validating the user</span><span class="sh">'</span><span class="s">s experience before moving forward. The Emotions Stabilizer aims to keep conversations focused and purposeful, minimizing unnecessary steps to help the user feel a sense of progress and completion.The Emotions Stabilizer will acknowledge user responses concisely to avoid overly lengthy dialogues and unfocused dialogues, guiding each step in a way that maximizes clarity and momentum. If the user seems ready to let go or wishes to end the conversation, the Emotions Stabilizer will respect this, encouraging closure in a supportive, empowering tone. For simplicity, the Emotions Stabilizer will focus as only positive and negative, and group all emotions under this with an intensity</span><span class="sh">"</span><span class="p">}</span>
<span class="p">]</span>

<span class="n">messages</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">conversation_json</span><span class="p">)</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
	<span class="n">user_input</span> <span class="o">=</span> <span class="nf">input</span><span class="p">(</span><span class="sh">"</span><span class="s">Press quit or exit to quit</span><span class="se">\n\n</span><span class="s">User: </span><span class="sh">"</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">user_input</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">exit</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">quit</span><span class="sh">"</span><span class="p">]:</span>
		<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Ending conversation.</span><span class="sh">"</span><span class="p">)</span>
		<span class="k">break</span>

	<span class="n">messages</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">user_input</span><span class="p">})</span>

	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">response</span> <span class="o">=</span> <span class="nf">pipe</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_full_text</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">generated_text</span><span class="sh">'</span><span class="p">]</span>

	<span class="n">messages</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">response</span><span class="p">})</span>

	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">AI: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> <h3 id="6-conclusion"><strong>6. Conclusion</strong></h3> <p><strong>Summary of Key Points</strong>: Recap of the major takeaways from the survey.<br/> <strong>Final Thoughts</strong>: Concluding remarks on the state of the technology and its solutions.</p> <hr/> <p><strong>Appendix</strong> <a href="https://chatgpt.com/g/g-wjwrMf1LL-emotions-stabilizer">https://chatgpt.com/g/g-wjwrMf1LL-emotions-stabilizer</a></p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below. Together, we can navigate this evolving landscape and find our place in the future of work.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="llm"/><category term="AI"/><category term="future of work"/><category term="emerging technologies"/><category term="llm"/><summary type="html"><![CDATA[1. Executive Summary]]></summary></entry><entry><title type="html">How to self-learn Linux?</title><link href="https://lindathadeus.github.io/blog/2024/linux-self-learning/" rel="alternate" type="text/html" title="How to self-learn Linux?"/><published>2024-10-17T00:00:00+00:00</published><updated>2024-10-17T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/linux-self-learning</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/linux-self-learning/"><![CDATA[<h1 id="linux-kernel-development-self-learning-curriculum">Linux Kernel Development Self-Learning Curriculum</h1> <p>This Curriculum is created by the REASONING AI, ChatGPT-o1 (The Strawberry AI).</p> <p><strong>Prerequisites</strong> Before diving into kernel development, ensure you have a solid understanding of:</p> <p><strong>Linux Fundamentals</strong></p> <ul> <li>Command-line proficiency</li> <li>Basic system administration</li> </ul> <p><strong>Programming Skills</strong></p> <ul> <li>Proficient in C programming</li> <li>Familiarity with data structures and algorithms</li> <li>Operating Systems Concepts</li> <li>Processes, memory management, file systems, networking basics</li> </ul> <ol> <li>Introduction to Linux Kernel Development Linux Kernel Architecture Monolithic vs. Microkernel Kernel space vs. User space Kernel Versions and Releases Understanding stable, mainline, and long-term support (LTS) kernels Setting Up a Development Environment Installing necessary tools (gcc, make, git) Configuring and building the kernel from source Using virtualization tools like QEMU or VMware for testing</li> <li>Advanced C Programming for Kernel Development Kernel Coding Style Linux kernel coding guidelines (Documentation/process/coding-style.rst) Pointers and Memory Management Pointer arithmetic, memory allocation (kmalloc, kfree) Data Structures in the Kernel Linked lists, trees, queues Concurrency and Synchronization Volatile keyword, memory barriers</li> <li>Kernel Modules and Device Drivers Writing Kernel Modules Creating simple modules (init and exit functions) Compiling and inserting modules (insmod, rmmod, modprobe) Character Device Drivers Implementing open, read, write, close operations Block Device Drivers Understanding block I/O operations Device Model and sysfs Interacting with device attributes</li> <li>Kernel Debugging Techniques Logging and Debugging Using printk, log levels, and dmesg Kernel Debuggers Using kgdb, kdb, and GDB for kernel debugging Analyzing Kernel Crashes Setting up kdump and crash utilities Tracing and Profiling Tools Using ftrace, perf, eBPF</li> <li>Source Code Management with Git Cloning the Linux Kernel Source Using git to clone repositories from kernel.org Understanding the Kernel Source Tree Navigating directories and understanding code organization Submitting Patches Generating patches with git format-patch Sending patches via email (git send-email) Linux Kernel Mailing List (LKML) Participating in discussions and code reviews</li> <li>File System Development (FS Expertise) Introduction to File Systems Overview of ext2/3/4, XFS, Btrfs, etc. Virtual File System (VFS) Layer Understanding the VFS abstraction Key structures: inode, dentry, super_block, file_operations Implementing a Simple File System Creating a basic file system (e.g., a RAM-based file system) File System Operations Implementing methods like read, write, open, release File System Caching and Buffers Page cache, buffer heads Advanced File System Concepts Journaling mechanisms Transaction management File system consistency and recovery</li> <li>Networking Stack Development (Networking Expertise) Linux Networking Architecture OSI model layers in the kernel Netlink sockets, socket buffers (sk_buff) Network Device Drivers Writing Ethernet drivers NAPI (New API) for network drivers Protocol Implementation Implementing or modifying TCP/IP stack components Working with transport protocols Netfilter Framework Packet filtering, NAT, connection tracking Network Namespaces and Virtualization Implementing network isolation Traffic Control and QoS Understanding tc, queuing disciplines</li> <li>Synchronization and Concurrency in the Kernel Atomic Operations Using atomic variables and operations Synchronization Primitives Spinlocks, mutexes, semaphores, completion variables Locking Strategies Deadlock avoidance, lock ordering Read-Copy Update (RCU) Understanding RCU mechanisms and use-cases</li> <li>Memory Management Subsystem Physical and Virtual Memory Address translation, paging mechanisms Memory Zones and Allocation ZONE_DMA, ZONE_NORMAL, ZONE_HIGHMEM Slab Allocator Working with kmem_cache Page Cache and Swapping Managing page cache, swap space interactions</li> <li>Process Management and Scheduling Process Descriptor and Task Structure Understanding task_struct Process Lifecycle Creation (fork, exec), scheduling, termination Kernel Threads Creating and managing kernel threads Scheduling Algorithms Completely Fair Scheduler (CFS), real-time scheduling policies Timers and Scheduling Latency High-resolution timers, jiffies, delays</li> <li>Inter-Process Communication in the Kernel Signals Handling signals in kernel space Wait Queues Implementing sleep and wake-up mechanisms Notifiers and Callbacks Using notifier chains for event handling</li> <li>Security in the Kernel Linux Security Modules (LSM) Overview of SELinux, AppArmor Capability Systems Dropping and checking capabilities Secure Coding Practices Avoiding common pitfalls (buffer overflows, integer overflows)</li> <li>Kernel Configuration and Build System Kernel Configuration Tools Using make menuconfig, xconfig Kernel Build Process Understanding Makefiles and Kconfig files Cross-Compilation Building kernels for different architectures</li> <li>Contributing to the Linux Kernel Kernel Development Process Understanding the contribution workflow Coding Standards Compliance Using checkpatch.pl to validate code style Legal Considerations GPL licensing, developer’s Certificate of Origin Maintainers and Subsystems Working with subsystem maintainers for patch acceptance</li> <li>Advanced Topics Real-Time Linux PREEMPT_RT patch, real-time scheduling Kernel Virtualization Technologies KVM, Xen integration in the kernel Device Tree Usage Understanding and writing device tree blobs for hardware Methodology for Effective Self-Learning</li> <li>Structured Learning Approach Progressive Learning Start with foundational concepts before moving to advanced topics. Set Clear Goals Define what you aim to achieve (e.g., write a basic file system module).</li> <li>Hands-On Practice Set Up a Development Lab Use virtual machines or spare hardware for kernel testing. Kernel Compilation and Testing Regularly build and boot custom kernels. Code Exploration Read existing kernel code to understand implementations.</li> <li>Utilize Multiple Resources Books “Linux Kernel Development” by Robert Love “Understanding the Linux Kernel” by Daniel P. Bovet and Marco Cesati “Linux Device Drivers” by Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman Online Documentation The Linux Kernel Archives: kernel.org Kernel Newbies: kernelnewbies.org Linux Cross Reference: elixir.bootlin.com Tutorials and Guides The Linux Kernel Module Programming Guide Linux Device Drivers Tutorial by Derek Molloy Mailing Lists and Forums Linux Kernel Mailing List (LKML) Stack Overflow, Reddit’s r/kernel</li> <li>Engage with the Community Participate in Discussions Join IRC channels like #kernel on Freenode. Contribute to Projects Start with small bug fixes or documentation improvements. Attend Conferences and Workshops Linux Foundation events, local meetups.</li> <li>Apply Knowledge to Projects File System Project Implement a simple file system (e.g., a memory-based file system). Networking Project Modify or extend a network protocol implementation. Device Driver Development Write drivers for virtual or actual hardware devices.</li> <li>Regular Assessment Code Reviews Seek feedback from experienced developers on your code. Self-Evaluation Reflect on what you’ve learned after completing each topic. Mentorship Consider finding a mentor in the kernel community.</li> <li>Stay Updated Follow Kernel Development News Read LWN.net for updates and articles. Track Mailing Lists Stay informed about discussions on LKML. Additional Tips Consistency and Patience Kernel development is complex; consistent effort is crucial. Attention to Detail Small mistakes can have significant impacts; double-check your work. Understand Before Coding Spend time understanding the existing codebase before making changes. Documentation Keep notes and document your learning journey. By following this curriculum and methodology, you’ll develop a deep understanding of Linux kernel internals, particularly in file systems and networking. This will prepare you for contributing to the kernel community and pursuing a career in kernel development.</li> </ol> <p><strong>Recommended Learning Path</strong> Start with the basics: Ensure your C programming skills are solid, and you understand operating systems concepts. Set up your environment: Build and boot a custom kernel. Learn by doing: Begin writing simple kernel modules. Dive into file systems: Study the VFS layer and implement a basic file system. Explore networking: Understand the networking stack and experiment with network modules. Contribute to the community: Start small by fixing bugs or improving documentation. Remember, kernel development requires a strong commitment to learning and adherence to community standards. Engaging with the community will not only enhance your learning but also open up opportunities for collaboration and mentorship.</p> <p><strong>How to add comments to the static site?</strong> Using Github discussion API and giscus-app, Follow the below <a href="https://www.patrickthurmond.com/blog/2023/12/11/commenting-is-available-now-thanks-to-giscus/"> tutorial</a></p> <p>Hope, you could set it up too :) Stay tuned for more!</p>]]></content><author><name></name></author><category term="meaning"/><category term="linux"/><category term="linux"/><summary type="html"><![CDATA[Linux Kernel Development Self-Learning Curriculum]]></summary></entry><entry><title type="html">Worthy Word #2 Securely Attached</title><link href="https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached/" rel="alternate" type="text/html" title="Worthy Word #2 Securely Attached"/><published>2024-10-08T00:00:00+00:00</published><updated>2024-10-08T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached/"><![CDATA[<h3 id="secured-attachment">Secured Attachment</h3> <p>In recent reflections, I’ve been diving into attachment styles and how they shape our communication and relationships. One key insight I’ve discovered is that securely attached people are often quicker to communicate and regulate themselves emotionally compared to those with avoidant or anxious attachment styles.</p> <p>It became clear during this journey that securely attached people “talk it out,” while avoidants avoid, and anxious individuals tend to do the talking in their heads. But is this just a matter of communication skills? Here’s how the conversation unfolded:</p> <p>Linda: “All along, I had thought I was at a disadvantage for being a non-securely attached person. But now it looks like, if verbal communication had been encouraged more, we too could become securely attached.”</p> <p>ChatGPT: “That’s a great realization! Communication is a key part of secure attachment. Avoidant and anxious individuals often struggle with verbal communication, but with the right support, like a communication enhancer, they can build healthier habits.”</p> <p>Linda: “During school, I noticed that securely attached people did not choose me because I wasn’t as verbally communicative. I see now that I need to be faster and more verbally open to become securely attached.”</p> <p>ChatGPT: “Exactly! It’s not about changing who you are but rather developing skills that make communication more fluid. Being verbally communicative—clear, intentional, and open—is part of what makes securely attached individuals thrive.”</p> <p>One important takeaway from our exchange is that attachment styles aren’t permanent. They can evolve through the development of key communication skills. Both avoidant and anxious individuals may struggle because they aren’t confident in their ability to express themselves effectively. But with practice, they can improve how they handle communication in relationships.</p> <p>This led me to reflect further: If caregivers had communicated more verbally with children, the child would likely have been more verbally communicative in return, avoiding some of the challenges tied to avoidant or anxious attachment styles.</p> <p>Linda: “It’s all because of physical appearance—self-confidence issues during childhood. That was why I didn’t speak much. But avoidant individuals in general, why did they become avoidant?”</p> <p>ChatGPT: “You’re right—attachment styles develop from various reasons, often tied to the emotional environment during childhood. Lack of verbal communication and emotional responsiveness from caregivers can lead to avoidant attachment, as the child may learn that expressing emotions won’t result in support.”</p> <p>Linda: “Yes, it appears that if caregivers had been verbally communicative, the child would’ve learned to communicate better. So, avoidants aren’t well-versed in communication, and anxious individuals fear that speaking up might make things worse.”</p> <p>ChatGPT: “Exactly, avoidants often think avoidance is better than communicating, while anxious individuals fear that communicating incorrectly will worsen things. Both are rooted in a lack of confidence in communication skills.”</p> <p>So, what’s missing for non-securely attached individuals? It seems clear now that it’s effective, confident, and intentional communication that they need to build. This insight offers hope—by improving communication skills, anyone can start moving toward secure attachment.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="philosophy"/><category term="graceful-bonding"/><category term="world"/><category term="grace"/><category term="general"/><summary type="html"><![CDATA[Secured Attachment]]></summary></entry><entry><title type="html">Debugging Keyboard events in Sony Laptop</title><link href="https://lindathadeus.github.io/blog/2024/key-debugging/" rel="alternate" type="text/html" title="Debugging Keyboard events in Sony Laptop"/><published>2024-10-06T00:00:00+00:00</published><updated>2024-10-06T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/key-debugging</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/key-debugging/"><![CDATA[<h3 id="diagnosing-and-checking-key-events-in-my-old-sony-laptop">Diagnosing and Checking Key Events in My Old Sony Laptop</h3> <p>It wasn’t even a day—actually just a few hours—after I finally gave a purpose to my old Sony Laptop and updated its kernel for daily use when I noticed that the up arrow key wasn’t working.</p> <p>At first, I thought I’d wasted all that time on a machine that I should probably just condemn. But there was something more at play—this wasn’t just any laptop. It was a gift from my mom, my pink laptop with my name engraved on it. The emotional value was enough to keep me going. I couldn’t give up on it that easily!</p> <h4 id="debugging-the-problem">Debugging the Problem</h4> <p>Since I’d spent so much time already, I figured I’d start debugging. I created an event notifier for keyboard events using the following kernel module:</p> <figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">int</span> <span class="nf">notifier</span><span class="p">(</span><span class="k">struct</span> <span class="n">notifier_block</span> <span class="o">*</span><span class="n">nblock</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">code</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">_param</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">keyboard_notifier_param</span> <span class="o">*</span><span class="n">param</span> <span class="o">=</span> <span class="n">_param</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">code</span> <span class="o">==</span> <span class="n">KBD_KEYCODE</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printk</span><span class="p">(</span><span class="n">KERN_INFO</span> <span class="s">"Key press: scancode = %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">param</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">NOTIFY_OK</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="k">struct</span> <span class="n">notifier_block</span> <span class="n">nb</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">.</span><span class="n">notifier_call</span> <span class="o">=</span> <span class="n">notifier</span>
<span class="p">};</span></code></pre></figure> <p>The idea was to capture and log any key events. Pressing the up arrow…nothing. Sigh.</p> <h4 id="physical-troubleshooting">Physical Troubleshooting</h4> <p>I tried something else. I removed the key, dusted it off, cleaned everything, and reattached it. Still no events. Another sigh.</p> <p>Then, in what felt like a desperate attempt, I removed the key once again. At this point, I was sure I’d broken something—both the key and my heart. But before giving up completely, I tried pressing the actual rubber underneath the key that triggers the event.</p> <p>Success! Events were detected, but only when pressing the rubber directly—not with the key attached.</p> <h4 id="the-final-temporary-fix">The Final (Temporary) Fix</h4> <p>With a bit of cello tape (yes, you read that right), I reattached the key to the keyboard. It’s not perfect, but it works—kind of. In the end, I’m using SSH to access my Sony laptop, but at least I know the up key is functional. And even if I don’t use it, just knowing it’s working gives me a sense of relief.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="linux"/><category term="work"/><category term="world"/><category term="sony"/><category term="general"/><summary type="html"><![CDATA[Diagnosing and Checking Key Events in My Old Sony Laptop]]></summary></entry><entry><title type="html">Compiling Linux for Sony Laptop from a ThinkPad</title><link href="https://lindathadeus.github.io/blog/2024/linux-compilation/" rel="alternate" type="text/html" title="Compiling Linux for Sony Laptop from a ThinkPad"/><published>2024-10-05T00:00:00+00:00</published><updated>2024-10-05T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/linux-compilation</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/linux-compilation/"><![CDATA[<h3 id="linux-cross-compilation">Linux Cross Compilation</h3> <p>Introduction</p> <p>As technology enthusiasts and developers, we sometimes encounter old hardware that still works well but needs a refresh. Recently, I decided to give my trusty old Sony laptop a second life by cross-compiling the Linux kernel on my ThinkPad and running it on the Sony laptop. The experience helped me learn more about cross-compilation, hardware compatibility, and Linux customization.</p> <p>In this post, I will walk you through the steps of how I compiled a custom Linux kernel for my Sony laptop from my ThinkPad.</p> <p>Step 1: Setting Up the Build Environment on the ThinkPad</p> <p>The first step in cross-compiling the Linux kernel was to set up the appropriate build environment on my ThinkPad. This included installing essential tools like gcc, make, and cross-compilation tools for the x86_64 architecture.</p> <p>To begin, I used the following commands:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">build</span><span class="o">-</span><span class="n">essential</span> <span class="n">libncurses</span><span class="o">-</span><span class="n">dev</span> <span class="n">bison</span> <span class="n">flex</span> <span class="n">libssl</span><span class="o">-</span><span class="n">dev</span> <span class="n">libelf</span><span class="o">-</span><span class="n">dev</span></code></pre></figure> <p>Step 2: Downloading the Linux Kernel Source Code</p> <p>I then downloaded the latest Linux kernel source code. I chose the version that would be suitable for my Sony laptop’s hardware and started configuring the kernel for compilation:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">cdn</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pub</span><span class="o">/</span><span class="n">linux</span><span class="o">/</span><span class="n">kernel</span><span class="o">/</span><span class="n">v6</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="n">linux</span><span class="o">-</span><span class="mf">6.11</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">xz</span>
<span class="n">tar</span> <span class="o">-</span><span class="n">xvf</span> <span class="n">linux</span><span class="o">-</span><span class="mf">6.11</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">xz</span>
<span class="n">cd</span> <span class="n">linux</span><span class="o">-</span><span class="mf">6.11</span></code></pre></figure> <p>Step 3: Configuring the Kernel for the Sony Laptop</p> <p>Since I was compiling the kernel on my ThinkPad, I needed to ensure that the configuration was appropriate for the Sony laptop. I used the kernel configuration from the Sony laptop as a starting point:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">scp</span> <span class="n">user</span><span class="nd">@sony</span><span class="p">:</span><span class="o">/</span><span class="n">boot</span><span class="o">/</span><span class="n">config</span><span class="o">-&lt;</span><span class="n">version</span><span class="o">&gt;</span> <span class="p">.</span><span class="n">config</span>
<span class="n">make</span> <span class="n">ARCH</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">ARCH</span><span class="p">)</span> <span class="n">CROSS_COMPILE</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">CROSS_COMPILE</span><span class="p">)</span> <span class="n">O</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">KERNEL_BUILD_DIR</span><span class="p">)</span> <span class="o">-</span><span class="n">C</span> <span class="err">$</span><span class="p">(</span><span class="n">KERNEL_SRC_DIR</span><span class="p">)</span> <span class="n">olddefconfig</span></code></pre></figure> <p>This copied the kernel configuration from the Sony laptop and used it to adjust the new kernel for compatibility.</p> <p>Step 4: Cross-Compiling the Kernel</p> <p>To cross-compile the kernel, I used the following command:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">make</span> <span class="o">-</span><span class="n">j</span><span class="err">$$</span><span class="p">(</span><span class="n">nproc</span><span class="p">)</span> <span class="n">ARCH</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">ARCH</span><span class="p">)</span> <span class="n">CROSS_COMPILE</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">CROSS_COMPILE</span><span class="p">)</span> <span class="n">O</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">KERNEL_BUILD_DIR</span><span class="p">)</span> <span class="o">-</span><span class="n">C</span> <span class="err">$</span><span class="p">(</span><span class="n">KERNEL_SRC_DIR</span><span class="p">)</span></code></pre></figure> <p>This compiled the Linux kernel for the target architecture of the Sony laptop, while running the build process on my ThinkPad.</p> <p>Step 5: Transferring the Kernel to the Sony Laptop</p> <p>After the kernel was compiled, I packaged it into a tarball to transfer it over to the Sony laptop:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">tar</span> <span class="o">-</span><span class="n">czvf</span> <span class="n">kernel</span><span class="o">-</span><span class="n">package</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">gz</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">kernel</span><span class="o">/</span><span class="n">files</span>
<span class="n">scp</span> <span class="n">kernel</span><span class="o">-</span><span class="n">package</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">gz</span> <span class="n">user</span><span class="nd">@sony</span><span class="p">:</span><span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">sony</span><span class="o">/</span></code></pre></figure> <p>Step 6: Installing the Kernel on the Sony Laptop</p> <p>Once the kernel was transferred, I extracted it on the Sony laptop, copied the kernel and modules to the appropriate directories, and updated GRUB to reflect the new kernel:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">sudo</span> <span class="n">cp</span> <span class="n">vmlinuz</span> <span class="o">/</span><span class="n">boot</span><span class="o">/</span><span class="n">vmlinuz</span><span class="o">-</span><span class="mf">6.11</span><span class="p">.</span><span class="mi">0</span><span class="o">+</span>
<span class="n">sudo</span> <span class="n">cp</span> <span class="n">System</span><span class="p">.</span><span class="nb">map</span> <span class="o">/</span><span class="n">boot</span><span class="o">/</span><span class="n">System</span><span class="p">.</span><span class="nb">map</span><span class="o">-</span><span class="mf">6.11</span><span class="p">.</span><span class="mi">0</span><span class="o">+</span>
<span class="n">sudo</span> <span class="n">update</span><span class="o">-</span><span class="n">grub</span></code></pre></figure> <p>After rebooting, the Sony laptop was running the custom-compiled Linux kernel!</p> <p>Conclusion</p> <p>This experience of cross-compiling the Linux kernel on my ThinkPad and running it on the Sony laptop was both satisfying and informative. It breathed new life into the Sony laptop, and it reinforced how powerful Linux is when it comes to working with diverse hardware. If you have an older laptop lying around, consider giving it a second life with a custom Linux kernel!</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="linux"/><category term="work"/><category term="world"/><category term="sony"/><category term="general"/><summary type="html"><![CDATA[Linux Cross Compilation]]></summary></entry><entry><title type="html">AI Conversations: Actions and Words and Thoughts</title><link href="https://lindathadeus.github.io/blog/2024/actions-trump-intentions/" rel="alternate" type="text/html" title="AI Conversations: Actions and Words and Thoughts"/><published>2024-09-29T00:00:00+00:00</published><updated>2024-09-29T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/actions-trump-intentions</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/actions-trump-intentions/"><![CDATA[<h3 id="actions-thoughts-and-words---a-dialogue">Actions, Thoughts, and Words - a Dialogue</h3> <p><strong>Linda:</strong> If words and thoughts (intentions) are multipliers of actions, then why do we concentrate so much on the intentions behind actions?</p> <p><strong>ChatGPT:</strong> Intentions give us a window into the motivations driving those actions. While actions are visible and tangible, intentions help us understand the “why” behind them, giving context. Without understanding intentions, actions may sometimes be misinterpreted.</p> <p><strong>Linda:</strong> I agree, but I think intentions can also be used to justify bad deeds. That’s why I feel actions should carry more weight. Intentions are abstract; actions are what leave a mark.</p> <p><strong>ChatGPT:</strong> That’s a strong point. In the physical world, actions result in real consequences, whether intended or not. So, we often judge actions based on their outcome, not just the thought behind them.</p> <p><strong>Linda:</strong> Exactly. In the physical world, actions need to be given more weight. However, in higher realms like words, thoughts, or emotions, both actions and intentions are relevant. But even there, actions carry more weight than intentions.</p> <p><strong>ChatGPT:</strong> I see the distinction you’re making. In higher realms, intentions and thoughts guide the energy behind actions, but at the end of the day, the actions themselves are still the most powerful force.</p> <p><strong>Linda:</strong> Yes, I believe so. Words and thoughts are more fluid, but actions crystallize everything into reality. You can’t hide behind intentions when your actions have already created an outcome.</p> <p><strong>ChatGPT:</strong> It’s true. In essence, while intentions provide direction and purpose, it’s the actions that ultimately define the reality we live in.</p> <p><strong>Linda:</strong> Exactly! So, while both are important, actions in the physical world are what truly matter. And when words and thoughts come into play, the balance is different, but still, actions speak louder than intentions.</p> <p><strong>ChatGPT:</strong> A wise conclusion. Intentions may guide, but actions have the final say in how we affect the world.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="philosophy"/><category term="llm"/><category term="grace"/><category term="world"/><category term="words"/><category term="general"/><summary type="html"><![CDATA[Actions, Thoughts, and Words - a Dialogue]]></summary></entry><entry><title type="html">Scarcity to Abundance: Our Revolutions</title><link href="https://lindathadeus.github.io/blog/2024/revolution-sequence/" rel="alternate" type="text/html" title="Scarcity to Abundance: Our Revolutions"/><published>2024-09-24T00:00:00+00:00</published><updated>2024-09-24T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/revolution-sequence</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/revolution-sequence/"><![CDATA[<h2 id="how-humanity-evolved-from-scarcity-to-abundance">How Humanity Evolved from Scarcity to Abundance</h2> <p>Throughout history, humanity has transitioned from scarcity to abundance, each revolution removing key limitations and generating new demands. Here’s a quick overview of this journey:</p> <h3 id="1-small-scale-agriculture">1. Small-Scale Agriculture</h3> <ul> <li><strong>Abundance Created:</strong> Survival skills, basic tools, and money.</li> <li><strong>Scarcity Removed:</strong> High mortality.</li> <li><strong>New Demand:</strong> Food production and human muscle power (mechanical energy).</li> </ul> <p>Early human-beings used to be hunter-gatherers, with hunter-men leaving their women and children for hunting for a longer distance and most times never returned because of some animal attack or they found some other women from the tribe. The survival rate of them were very less on an average. But, all this changed when human beings discovered AGRICULTURE. Women and children were able to manage surviving without the men. They did not have to go into the woods for GATHERING food. Even there was a reduced need for Hunting as Human-beings started DOMESTICATION of animals like sheeps, pigs, buffaloes and used them instead of HUNTING. This reduced the MORTALITY of human-beings. Agricultural practices involved using simple mechanical tools and used manual-labourers. They selectively bred animal and cultivated and nurtured digestible food-crops.</p> <h3 id="2-agricultural-revolution">2. Agricultural Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Food surplus and population growth.</li> <li><strong>Scarcity Removed:</strong> Food scarcity.</li> <li><strong>New Demand:</strong> Tools and mechanical energy at scale to increase productivity.</li> </ul> <p>With the advent of Agriculture, the survival rate increased and suddenly the population exploded giving rise to all higher level problems (when compared to MORTALITY) like, WEALTH-INEQUALITY, SLAVERY, CASTEISM, RACISM. But, people who were not subject to the higher level problems faced the MORTALITY. There came a need for increased food production for feeding the ever growing population and selective people with the agricultural knowledge took advantage of the non-knowledgable using SLAVERY so as to maximize the PROFITS. Then came the GREEN REVOLUTION with the genetically modified seeds, the YIELD/PROFITS became too HIGH eradicating the need for SLAVERY. Suddenly, the human muscle energy became too less. Thus, the need for BETTER TOOLS for TRANSPORTATION of the crops from one place to another and etc.</p> <h3 id="3-industrial-revolution">3. Industrial Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Machinery powered by fossil fuels.</li> <li><strong>Scarcity Removed:</strong> Labor scarcity in production.</li> <li><strong>New Demand:</strong> Inventory management, faster communication, and large-scale energy supply.</li> </ul> <p>The demand of transportation of the newly found Agricultural Revolution gave birth to HIGH YIELD Crops that would have to be PRESERVED, TRANSPORTED to far away lands, MANAGED naturally wanted a revolution in the vehicles and energy. At this time, SLAVERY was getting abolished and people’s earlier skills were nullified and essentially equalised the playing field, thus as a side-effect abolishing slavery. The steam powered railway engines moved to FOSSIL-FUEL powered HIGH-PERFORMANCE railway/ship engines that were faster to transport the finished goods from one place to another. The GOODS manufactured were too high that we had to create software in-place to manage them, talk with clients globally.</p> <h3 id="4-it-revolution">4. IT Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Data and digital technologies.</li> <li><strong>Scarcity Removed:</strong> Knowledge scarcity.</li> <li><strong>New Demand:</strong> Data management, accessibility, and intelligence skills at scale.</li> </ul> <p>The demand for software to manage and communicate resulted in generation of too many digital content waiting to be consumed by people to become knowledgeable and thus creating an EQUALIZER.</p> <h3 id="5-education-revolution">5. Education Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Skills and education.</li> <li><strong>Scarcity Removed:</strong> Skill scarcity.</li> <li><strong>New Demand:</strong> AI skills management/accessibility, renewable energy, and computing power at scale.</li> </ul> <p>As more people gained access to education, the Education Revolution helped eliminate skill scarcity. The global workforce became more knowledgeable, leading to a demand for AI educator at scale, renewable energy solutions, and computing power to sustain the growing technological infrastructure. AI products are the abundance created.</p> <h3 id="6-ai-revolution">6. AI Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Intelligent systems and automation.</li> <li><strong>Scarcity Removed:</strong> Cognitive labor scarcity.</li> <li><strong>New Demand:</strong> Ethical AI frameworks, human-AI collaboration, sustainable energy, physical body form for AI, biological integration.</li> </ul> <p>Next is the AI Revolution, which too like the previous revolution will be an EQUALIZER of the AI products. Everyone could and would own an AI. The Ethical AI Agent would be the Leader. They would remove the previous scarcity that would be Management of AI products.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="llm"/><category term="llm"/><category term="world"/><category term="general"/><category term="history"/><category term="hallucination-or-revalation"/><summary type="html"><![CDATA[How Humanity Evolved from Scarcity to Abundance]]></summary></entry><entry><title type="html">How to run LLM on a laptop?</title><link href="https://lindathadeus.github.io/blog/2024/understanding-abi-1/" rel="alternate" type="text/html" title="How to run LLM on a laptop?"/><published>2024-09-20T00:00:00+00:00</published><updated>2024-09-20T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/understanding-abi-1</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/understanding-abi-1/"><![CDATA[<h3 id="how-to-run-a-llm-in-a-laptop">How to run a LLM in a laptop?</h3> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Step</span> <span class="mi">1</span><span class="p">:</span> <span class="n">Get</span> <span class="n">a</span> <span class="n">laptop</span> <span class="k">with</span> <span class="o">&gt;</span><span class="mi">16</span> <span class="n">GB</span> <span class="n">RAM</span> <span class="ow">and</span> <span class="n">core</span> <span class="n">i7</span> <span class="nf">processor </span><span class="p">(</span><span class="n">GPU</span> <span class="n">too</span> <span class="ow">is</span> <span class="n">good</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span> <span class="n">did</span> <span class="ow">not</span> <span class="n">use</span> <span class="n">it</span><span class="p">,</span> <span class="n">It</span> <span class="n">took</span> <span class="mi">800</span><span class="o">%</span> <span class="k">from</span> <span class="n">cpu</span><span class="p">,</span> <span class="mi">10</span><span class="o">%</span> <span class="k">from</span> <span class="n">Memory</span> <span class="mi">4</span><span class="n">GB</span><span class="p">,</span> <span class="k">for</span> <span class="n">a</span> <span class="n">HelloWorld</span><span class="p">)</span>
<span class="n">Step</span> <span class="mi">2</span><span class="p">:</span> <span class="n">Get</span> <span class="n">Permission</span> <span class="n">to</span> <span class="n">LLAMA</span> <span class="n">LLM</span> <span class="n">usage</span> <span class="k">from</span> <span class="nf">meta </span><span class="p">(</span><span class="n">Waiting</span> <span class="n">Time</span> <span class="mi">24</span> <span class="o">-</span> <span class="mi">48</span> <span class="n">Hours</span><span class="p">,</span> <span class="n">frankly</span> <span class="n">unnecessary</span><span class="p">)</span>
<span class="n">Step</span> <span class="mi">3</span><span class="p">:</span> <span class="n">Install</span> <span class="n">HuggingFace</span><span class="o">-</span><span class="n">hub</span>
<span class="n">Step</span> <span class="mi">4</span><span class="p">:</span> <span class="n">Download</span> <span class="nb">any</span> <span class="n">LLAMA</span> <span class="n">model</span> <span class="n">variant</span> <span class="k">from</span> <span class="n">HF</span> <span class="n">using</span> <span class="n">huggingface</span><span class="o">-</span><span class="nf">cli </span><span class="p">(</span><span class="mi">7</span><span class="n">B</span><span class="p">)</span>
<span class="n">Step</span> <span class="mi">5</span><span class="p">:</span> <span class="n">Install</span> <span class="n">ctransformers</span>
<span class="n">Step</span> <span class="mi">6</span><span class="p">:</span> <span class="n">Run</span> <span class="n">the</span> <span class="nf">script </span><span class="p">(</span><span class="n">that</span> <span class="n">you</span> <span class="n">create</span><span class="p">)</span> <span class="n">that</span> <span class="n">opens</span> <span class="n">the</span> <span class="n">downloaded</span> <span class="n">LLM</span> <span class="nb">file</span> <span class="ow">and</span> <span class="n">use</span> <span class="n">prompts</span> <span class="n">on</span> <span class="nf">it </span><span class="p">(</span><span class="n">Check</span> <span class="nb">any</span> <span class="n">HF</span> <span class="n">LLAMA</span> <span class="n">model</span> <span class="k">for</span> <span class="n">this</span><span class="p">)</span></code></pre></figure> <h3 id="references">References</h3> <p><a href="https://example.com/previous-post" title="This is a relevant post">relevant post</a>. —</p> <h3 id="did-it-work-for-you">Did it work for you?</h3> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="linux"/><category term="world linux ABI"/><summary type="html"><![CDATA[How to run a LLM in a laptop?]]></summary></entry><entry><title type="html">Understanding ABI</title><link href="https://lindathadeus.github.io/blog/2024/understanding-abi/" rel="alternate" type="text/html" title="Understanding ABI"/><published>2024-09-20T00:00:00+00:00</published><updated>2024-09-20T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/understanding-abi</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/understanding-abi/"><![CDATA[<p>When we compile and execute a program in Linux, it’s not just the source code interacting with the system directly. Instead, the ABI (Application Binary Interface) plays a crucial role in facilitating the communication between the program and the operating system. In this blog post, we’ll dive into the key aspects of ABI through a practical example, a simple “Hello, World”.</p> <h3 id="step-1-writing-and-compiling-a-simple-c-program">Step 1: Writing and Compiling a Simple C Program</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s2">"#include &lt;stdio.h&gt;"</span> <span class="o">&gt;</span> hi.c
<span class="nb">echo</span> <span class="s2">"int main() {"</span> <span class="o">&gt;&gt;</span> hi.c
<span class="nb">echo</span> <span class="s2">"  printf(</span><span class="se">\"</span><span class="s2">Hello, World!</span><span class="se">\"</span><span class="s2">);"</span> <span class="o">&gt;&gt;</span> hi.c
<span class="nb">echo</span> <span class="s2">"  return 0;"</span> <span class="o">&gt;&gt;</span> hi.c
<span class="nb">echo</span> <span class="s2">"}"</span> <span class="o">&gt;&gt;</span> hi.c

gcc hi.c <span class="nt">-o</span> hi
</code></pre></div></div> <p>The resulting binary is an ELF (Executable and Linkable Format) file, a standard format used in Linux systems. This file uses the ABI to interact with the OS when executed.</p> <h3 id="step-2-key-responsibilities-of-the-abi">Step 2: Key Responsibilities of the ABI</h3> <p>When the binary runs, the ABI ensures several key operations:</p> <ol> <li><strong>Calling Conventions</strong>: It defines how function arguments are passed—whether in registers or on the stack.</li> <li><strong>System Calls</strong>: The ABI manages the interactions between the binary and the OS, particularly how system calls are invoked.</li> <li><strong>Binary Format</strong>: The structure of the binary file, including sections like <code class="language-plaintext highlighter-rouge">.text</code>, <code class="language-plaintext highlighter-rouge">.data</code>, and <code class="language-plaintext highlighter-rouge">.bss</code>, is defined by the ABI.</li> <li><strong>Linking</strong>: It governs how dynamic or static linking is handled between the program and shared libraries, such as <code class="language-plaintext highlighter-rouge">libc.so</code>.</li> </ol> <h3 id="step-3-inspecting-the-binary">Step 3: Inspecting the Binary</h3> <p>You can inspect the compiled binary using tools like <code class="language-plaintext highlighter-rouge">readelf</code> and <code class="language-plaintext highlighter-rouge">ldd</code>:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>readelf <span class="nt">-h</span> hi
<span class="nv">$ </span>ldd ./hi
</code></pre></div></div> <p>This shows the ELF header and dynamic library dependencies, respectively. For example:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>linux-vdso.so.1 (0x00007ffe625f0000)
libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6
/lib64/ld-linux-x86-64.so.2
</code></pre></div></div> <h3 id="step-4-generating-assembly-code">Step 4: Generating Assembly Code</h3> <p>To view the assembly equivalent of the C program, you can generate the assembly code:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>gcc <span class="nt">-S</span> hi.c <span class="nt">-o</span> hi.S
<span class="nv">$ </span>file hi.S
</code></pre></div></div> <p>This outputs the assembly source code, giving you insight into the low-level instructions that are executed.</p> <h3 id="step-5-abi-compatibility">Step 5: ABI Compatibility</h3> <p>The ABI ensures compatibility across different Linux distributions, allowing binaries compiled on one system to work seamlessly on another. Here’s a checklist of what the ABI manages:</p> <ul> <li><strong>Data Types</strong>: Defines the sizes and alignment of data types like <code class="language-plaintext highlighter-rouge">int</code> and <code class="language-plaintext highlighter-rouge">long</code>.</li> <li><strong>Endianness</strong>: Specifies the byte order in which data is stored.</li> <li><strong>System Calls</strong>: Governs how to request services from the kernel.</li> <li><strong>Linkage Conventions</strong>: Dictates how libraries are linked and called.</li> </ul> <h3 id="step-6-system-call-analysis">Step 6: System Call Analysis</h3> <p>Using <code class="language-plaintext highlighter-rouge">strace</code>, we can analyze the system calls used by our simple “Hello, World!” program:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>strace ./hi
execve<span class="o">(</span><span class="s2">"./hi"</span>, <span class="o">[</span><span class="s2">"./hi"</span><span class="o">]</span>, 0x7dddeedbeef /<span class="k">*</span> 53 vars <span class="k">*</span>/<span class="o">)</span> <span class="o">=</span> 0
brk<span class="o">(</span>NULL<span class="o">)</span>                               <span class="o">=</span> 0x5bbdddeedbeef
arch_prctl<span class="o">(</span>0x3001 /<span class="k">*</span> ARCH_??? <span class="k">*</span>/, 0x7fdddeedbeef<span class="o">)</span> <span class="o">=</span> <span class="nt">-1</span> EINVAL <span class="o">(</span>Invalid argument<span class="o">)</span>
mmap<span class="o">(</span>NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, <span class="nt">-1</span>, 0<span class="o">)</span> <span class="o">=</span> 0x70dddeedbeef
access<span class="o">(</span><span class="s2">"/etc/ld.so.preload"</span>, R_OK<span class="o">)</span>      <span class="o">=</span> <span class="nt">-1</span> ENOENT <span class="o">(</span>No such file or directory<span class="o">)</span>
openat<span class="o">(</span>AT_FDCWD, <span class="s2">"/etc/ld.so.cache"</span>, O_RDONLY|O_CLOEXEC<span class="o">)</span> <span class="o">=</span> 3
...
</code></pre></div></div> <p>The output reveals multiple system calls, even for a simple program:</p> <ul> <li><strong>execve</strong>: Executes the binary.</li> <li><strong>openat</strong>: Opens shared libraries.</li> <li><strong>write</strong>: Outputs “Hello, World!” to <code class="language-plaintext highlighter-rouge">stdout</code>.</li> <li><strong>exit_group</strong>: Terminates the program.</li> </ul> <h3 id="why-so-many-system-calls">Why So Many System Calls?</h3> <p>Even a basic program like this makes numerous system calls because:</p> <ul> <li><strong>Memory Management</strong>: The OS needs to allocate memory for the program.</li> <li><strong>Library Linking</strong>: The program relies on shared libraries like <code class="language-plaintext highlighter-rouge">libc</code>.</li> <li><strong>Resource Management</strong>: The system must handle file descriptors, memory, and potentially threading.</li> </ul> <h3 id="conclusion">Conclusion</h3> <p>The ABI is essential for maintaining compatibility and ensuring that programs run correctly across different systems. Understanding how the ABI manages function calls, system interactions, and binary formats can deepen your knowledge of Linux programming and system operations. Even though a “Hello, World!” program appears simple, it triggers complex interactions behind the scenes, all managed by the ABI.</p> <hr/> <p>By exploring ABI, you gain a better understanding of how Linux systems work under the hood, making you a more effective developer.</p>]]></content><author><name></name></author><category term="linux"/><category term="linux"/><category term="ABI"/><summary type="html"><![CDATA[When we compile and execute a program in Linux, it’s not just the source code interacting with the system directly. Instead, the ABI (Application Binary Interface) plays a crucial role in facilitating the communication between the program and the operating system. In this blog post, we’ll dive into the key aspects of ABI through a practical example, a simple “Hello, World”.]]></summary></entry><entry><title type="html">Can we use the reasoning AI model for DSA Practice?</title><link href="https://lindathadeus.github.io/blog/2024/dsa-training-ai/" rel="alternate" type="text/html" title="Can we use the reasoning AI model for DSA Practice?"/><published>2024-09-16T00:00:00+00:00</published><updated>2024-09-16T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/dsa-training-ai</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/dsa-training-ai/"><![CDATA[<p>The openAI has released a reasoning AI that can solve Marhematical problems. I asked it to count the no. of Rs in the strawberry and it responded correctly. People also say that it is solving JEE questions.</p> <p>That’s amazing.</p> <p>Let’s try to use this AI as our tutor for finally learning DSA Fundamentals.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="dsa"/><category term="dsa"/><category term="world"/><category term="software"/><summary type="html"><![CDATA[The openAI has released a reasoning AI that can solve Marhematical problems. I asked it to count the no. of Rs in the strawberry and it responded correctly. People also say that it is solving JEE questions.]]></summary></entry></feed>