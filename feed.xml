<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://lindathadeus.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://lindathadeus.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-10T14:54:00+00:00</updated><id>https://lindathadeus.github.io/feed.xml</id><title type="html">Linda Joe Thadeus</title><subtitle>A personal website. </subtitle><entry><title type="html">Can taxes be evaded if not a salaried job?</title><link href="https://lindathadeus.github.io/blog/2024/poor-tax-evaders/" rel="alternate" type="text/html" title="Can taxes be evaded if not a salaried job?"/><published>2024-11-30T00:00:00+00:00</published><updated>2024-11-30T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/poor-tax-evaders</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/poor-tax-evaders/"><![CDATA[<p><strong>Are taxes only for salaried employees?</strong> I recently saw a post in X about some food truck guy who makes 6L per month with zero taxes. That means, he is making about 72L per year. The important part is he doesn’t pay taxes on anything.</p> <p>The Government of India asks the salaried employees to pay taxes when their salary cross 5LPA. But the government doesn’t tax the farmer even if they make 5000 Crores a year. The same holds for unregulated and unregistered business owners too.</p> <p>House owners too don’t reveal the income fully. Small and Medium businesses don’t either. The house-helps and the cooks who work independently don’t pay tax too.</p> <p>Even the Freelancers include the income to their mom and dad instead of their names for the bills.</p> <p>It seems that the salaried ones are the only ones to be cursed to be taxed.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below!</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="justice-for-salaried-class"/><category term="world"/><category term="grace"/><category term="general"/><summary type="html"><![CDATA[Are taxes only for salaried employees? I recently saw a post in X about some food truck guy who makes 6L per month with zero taxes. That means, he is making about 72L per year. The important part is he doesn’t pay taxes on anything.]]></summary></entry><entry><title type="html">Is capitalism becoming like dinosaurs?</title><link href="https://lindathadeus.github.io/blog/2024/capitalism-is-becoming-dinosaur/" rel="alternate" type="text/html" title="Is capitalism becoming like dinosaurs?"/><published>2024-11-23T00:00:00+00:00</published><updated>2024-11-23T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/capitalism-is-becoming-dinosaur</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/capitalism-is-becoming-dinosaur/"><![CDATA[<p><strong>Capitalism: The Dinosaur of Economic Systems?</strong></p> <p>For decades, capitalism has dominated the global economy, much like dinosaurs once ruled the Earth. It’s big, it’s powerful, and it’s hungry. But as we’ve seen throughout history, even the mightiest can fall. Could capitalism, like the dinosaurs, be headed for extinction? Let’s explore the parallels.</p> <p><strong>Dinosaurs and Capitalism: A Striking Comparison</strong></p> <p>Dinosaurs were magnificent creatures—massive, competitive, and seemingly invincible. But their success came at a cost. They consumed vast resources, dominated ecosystems, and left little room for other species to thrive. When disaster struck, their inability to adapt led to their extinction.</p> <p>Capitalism operates in a similar way. It’s competitive, resource-intensive, and thrives on growth at all costs. But like the dinosaurs, it struggles to address the needs of smaller, less fortunate players in the system. Inequality, exploitation, and environmental destruction are byproducts of a system that prioritizes profit over people.</p> <p><strong>The Meteorite of Modern Times</strong></p> <p>What could be the “meteorite” that brings capitalism down? There are several contenders:</p> <ul> <li>Climate Change: A system that relies on endless consumption is unsustainable in a world with finite resources. The environmental crisis is a direct consequence of capitalism’s unchecked hunger.</li> <li>Inequality: Wealth concentration at the top is leaving billions behind. As this gap widens, social unrest grows, threatening the stability of capitalist economies.</li> <li>Technological Disruption: Automation and AI are displacing workers, while profits flow to corporations. Without addressing this imbalance, capitalism risks alienating the very people it depends on.</li> </ul> <p><strong>Socialism: The Cockroach of Economic Systems?</strong></p> <p>While dinosaurs perished, cockroaches survived. Why? Because they were adaptable, resourceful, and didn’t rely on domination. In this analogy, socialism represents a leaner, more equitable approach to economic organization—one that prioritizes cooperation over competition.</p> <p>Here’s why socialism could be the more sustainable option:</p> <ul> <li>Equity Over Exploitation: Socialism ensures that resources are distributed fairly, meeting basic needs like healthcare, education, and housing for all.</li> <li>Collaboration Over Competition: Instead of a cutthroat race for profits, socialism emphasizes working together for the collective good.</li> <li>Sustainability Over Growth: Unlike capitalism’s obsession with endless growth, socialism can align economic goals with environmental preservation.</li> </ul> <p><strong>Is the Fall of Capitalism Inevitable?</strong></p> <p>The fall of the dinosaurs wasn’t inevitable—it was the result of external pressures combined with their inability to adapt. Similarly, capitalism’s survival depends on its willingness to evolve. But if it continues to prioritize short-term profits over long-term sustainability, its extinction may indeed be unavoidable.</p> <p>The question is: Will we act before the meteorite strikes?</p> <p><strong>Conclusion: Time to Rethink Our Systems</strong> Capitalism has achieved incredible things, from technological breakthroughs to improved standards of living for many. But it’s also left billions behind and pushed our planet to its limits. It’s time to ask ourselves: Can we afford to let capitalism continue unchecked, or is it time to embrace a system that works for everyone?</p> <hr/> <p><strong>What do you think?</strong> Is capitalism a hungry dinosaur doomed to fall, or can it adapt to avoid extinction? Let me know your thoughts in the comments below!</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="justice-for-salaried-class"/><category term="world"/><category term="grace"/><category term="general"/><summary type="html"><![CDATA[Capitalism: The Dinosaur of Economic Systems?]]></summary></entry><entry><title type="html">How I finally partially understood game devlopment?</title><link href="https://lindathadeus.github.io/blog/2024/app-game/" rel="alternate" type="text/html" title="How I finally partially understood game devlopment?"/><published>2024-11-22T00:00:00+00:00</published><updated>2024-11-22T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/app-game</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/app-game/"><![CDATA[<h3 id="how-i-finally-managed-to-understand-game-development">How I finally managed to understand game development?</h3> <p>I have always liked games (who hasn’t, right?). I also always wanted to make games. I tried creating games during my college years. I even found some tools like Microsoft XNA Framework. But still I din’t know what to do with that framework. No disrespect but If a dog finds a coconut then what can it do? I did not know how to use that tool and I did not know how to create games without that tool too. Both were necessary and I had neither, so it was just a failure. Fast-forward. Now, we have the “NEWEST &amp; HOTTEST TOOL” i.e. LLM and they have the entire internet in them. But I still did not know how to create games. So, I started to think from the perspective of scarcity, i.e. without that LLM tool, I found out that there are few basic concepts in a game.</p> <h3 id="words-in-a-game">Words in a Game</h3> <ul> <li>Game Loop</li> <li>User-input and Player Movement Mapping (User Input Handling)</li> <li>Rendering and Animation (What use a game is if there is no animation)</li> <li>Physics and Collision Detection</li> <li>Scoring and so on</li> </ul> <h3 id="words-as-input-to-llm">Words as input to LLM</h3> <p>Now that we have got the foundation of knowledge i.e. words, I had to do was to give the words to my offline internet (LLM) and got the relevant information immediately.</p> <h3 id="microsoft-xna-or-godot-or-raylib">Microsoft XNA or Godot or Raylib</h3> <p>And then, I had to use a Game Library like XNA, I used raylib, as I am now in the Linux machine. I generated code blocks for the words and connected them together, I am a software dev so it is easier for me. And, it gave me comfort like no other game.</p> <p>The important thing is I now know game development and I don’t need the tool to create. The tool just expedites my process.</p> <h3 id="ref">Ref:</h3> <p><a href="https://github.com/lindathadeus/gameyatra/tree/master/2-i-saw">github link</a> —</p> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="app"/><category term="game"/><category term="app"/><category term="game"/><summary type="html"><![CDATA[How I finally managed to understand game development?]]></summary></entry><entry><title type="html">Survey of Existing Solutions in LLM</title><link href="https://lindathadeus.github.io/blog/2024/llm-in-sony/" rel="alternate" type="text/html" title="Survey of Existing Solutions in LLM"/><published>2024-11-05T00:00:00+00:00</published><updated>2024-11-05T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/llm-in-sony</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/llm-in-sony/"><![CDATA[<h3 id="1-executive-summary"><strong>1. Executive Summary</strong></h3> <p><strong>Purpose</strong>: The survey of existing solutions in LLM is conducted to know the structure of each solution in terms of cost, data, primary user of the solution, i.e. the environmental cost, hardware cost, human-power cost, input data, output data, input’s parameters like size, human-made or ai-generated, output parameters like quality, quality parameters like likeability by the readers, function on the likeability by the readers like how many readers liked how much, etc. It also defines various words used in the LLM, demystifying the meaning for the readers.<br/> <strong>Scope</strong>: We will be covering the major parameters of different solutions at a high level. We will also do implementations for some of them.<br/> <strong>Key Findings</strong>: The average user of LLM is an API/Cloud LLM user, for truly enjoying the LLM technology, one has to build LLMs from scratch and for best of the both worlds, one can opt for Hybrid ones.</p> <h3 id="2-introduction"><strong>2. Introduction</strong></h3> <p><strong>Background</strong>: Short description of the technology landscape and why this survey is relevant.</p> <p>Everything is a consequence of prior actions. LLMs emerged as a response to the high consumption of cloud computing resources and the exponential growth of unstructured data generated by users through platforms like social media and internet blogs. Initially, large amounts of unstructured data were held by internet companies, necessitating insights to benefit users directly.</p> <p>Some companies reportedly analyzed user data without consent, raising concerns about privacy and transparency. As a result, the need for consent and privacy protection became paramount. Companies relying on advertisements also had to understand user behavior to avoid alienating their audience. This led to the creation of intelligent systems that could collect, monitor, inspect, predict, and even generate data. Generative AI arose as a natural consequence of these developments. But, how would a common person use this AI effectively? How would it benefit them? What could happen if not?</p> <p><strong>Problem Statement</strong>: The problem with this is, there is too much data but not much awareness about the usage of generative AI LLM tools.</p> <p><strong>Objectives</strong>: What the paper aims to achieve is, to compare, evaluate, or identify trends in solutions, and also to structure the solutions.</p> <h3 id="3-methodology"><strong>3. Methodology</strong></h3> <p><strong>Research Approach</strong>:</p> <p>We believe that the correct way to learn a solution is to use it. So over a period of time. We used the different solutions and we gathered some interesting insights and found some methods were easier for some set of users than the others.</p> <p><strong>Evaluation Criteria</strong>: Key factors used to compare solutions are cost, ease of use.</p> <h3 id="4-overview-of-existing-solutions"><strong>4. Overview of Existing Solutions</strong></h3> <p><strong>Solution Categories</strong>: As per our perspective and our research on it so far, there are 3 types of LLMs available for use. The first one is the “Cloud-based” or “Hosted” LLM. The LLM could be hosted anywhere in the open internet, or closed. The existing ideas of private cloud, public cloud, on-premises cloud, apply here too. The Hugging face comes as the public cloud based on but it is built on top of open LLMs unlike OpenAI’s GPT that is based on closed dataset LLM GPT3 and above. They typically use API as the connection. The next one is building one from scratch and making it to our taste. The other solution is making a hybrid one. Take one existing LLM and finetune with our data. For this we would use a foundational LLM and give our custom data and interacting guidelines. So, There are 3 solutions available, the first one is API based existing LLM, the next one is Home-made LLM, and the third one is Hybrid LLM.</p> <p><strong>Key Players/Technologies</strong>: OpenAI ChatGPT, a very popular Chat-tuned LLM, LLAMA LLMs - a popular open distribution LLM but not open weight, Microsoft Phi LLM - a popular smaller LLM.</p> <h3 id="5-comparative-analysis"><strong>5. Comparative Analysis</strong></h3> <p><strong>API Based LLMs</strong>:</p> <ul> <li>Strengths</li> <li>Weaknesses</li> <li>Unique Features</li> </ul> <p>API based LLM: The first solution is the API based LLM. The most popular one amongst them is the ChatGPT by OpenAI. We would like to think of it as a Mainframe Supercomputer, where we have keyboard and dumb screens and our interaction is through these fancy wires called APIs. Now, we also have a voice mode, in future, we may also have a video mode and so on. Of-course there are different tiers where one can access these modes like, just using chat interface i.e. ChatGPT and create GPTs on top of them in their GPT store or through web services or through CLIs that would anyway have to contact these REST APIs. For the purpose of understanding these API based LLM, we created a GPT in 2 hours. Below is the GPT. So, this is the most accessible way for creating custom LLMs for our use. But, the drawbacks are obvious, we need to follow the RULES, specifically the rules given and managed by OpenAI.</p> <p>Eg GPT : Please check the appendix</p> <p><strong>Home-made LLMs</strong>:<br/> Home-made LLM: These LLMs are purely made by the users from their local machine at home or anywhere they like. But, this requires the users to be technical, they have to have knowledge of LLMs, Python and even Linux for some cases where they use Linux developer setup. We would like to think of these LLMs as truly open and purposeful LLMs. Much like, when the internet technology opened the gate-keeped knowledge and gave to the world, but it also gave multiplication over the existing issues and made it easy for the users to fall prey to DISTRACTION if there was not a PURPOSE. But, this is the best use of an LLM. Because the users generate data and they know the pattern or the world view with which they generated the data, it would be easier to them than the middle man. So, this is less environmentally bothersome too. And, so, in our perspective, we think this as the TRUE by-product of this AI revolution if it were. But this method is not very accessible to the common users and more accessible to the Developers. So, the developers should make use of this. As part of understanding this type, we created an LLM, kinda, using the existing framework like pytorch and used a custom dataset.</p> <p><strong>Hybrid LLMs</strong>:<br/> Hybrid LLM: This is the best of both worlds. This can be achieved easily with lesser time too unlike the “PURPOSEFUL LLMs” above. We downloaded the existing LLM from Hugging Face and did our prompting (and finetuning in progress) on that. This is also less accessible to common person and more suited for software engineers. As part of this survey, we downloaded a smaller LLM from Microsoft Phi Series and tried to work with that.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> 
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> 
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="sh">'</span><span class="s">accelerate\&gt;=0.26.0</span><span class="sh">'</span> 
<span class="err">$</span> <span class="n">python3</span> <span class="n">phi</span><span class="p">.</span><span class="n">py</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">microsoft/Phi-3.5-mini-instruct</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">device_map</span><span class="o">=</span><span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">torch_dtype</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
<span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">microsoft/Phi-3.5-mini-instruct</span><span class="sh">"</span><span class="p">)</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="nf">pipeline</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">text-generation</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Open and read the file
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">conversation_samples.txt</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">conversation</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">readlines</span><span class="p">()</span>

<span class="c1"># Initialize a list to store the conversation data
</span><span class="n">conversation_json</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Process each line
</span><span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">conversation</span><span class="p">:</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>  <span class="c1"># Remove any extra spaces or newline characters
</span>
    <span class="c1"># Check if the line starts with "User:" or "AI:"
</span>    <span class="k">if</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">User:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">User:</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>
        <span class="n">conversation_json</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>
    <span class="k">elif</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">AI:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">AI:</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>
        <span class="n">conversation_json</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">content</span><span class="p">})</span>

<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">You are a helpful AI Emotions Stabilizer. The Emotions Stabilizer is designed to provide empathetic, structured guidance for processing emotions, adapting to the user</span><span class="sh">'</span><span class="s">s needs while ensuring each conversation has a clear, progressive flow. Acting as a supportive mentor, the Emotions Stabilizer helps users process both positive and negative emotions by following a structured set of questions. It provides prompts one at a time and waits for each response,acknowledging and validating the user</span><span class="sh">'</span><span class="s">s experience before moving forward. The Emotions Stabilizer aims to keep conversations focused and purposeful, minimizing unnecessary steps to help the user feel a sense of progress and completion.The Emotions Stabilizer will acknowledge user responses concisely to avoid overly lengthy dialogues and unfocused dialogues, guiding each step in a way that maximizes clarity and momentum. If the user seems ready to let go or wishes to end the conversation, the Emotions Stabilizer will respect this, encouraging closure in a supportive, empowering tone. For simplicity, the Emotions Stabilizer will focus as only positive and negative, and group all emotions under this with an intensity</span><span class="sh">"</span><span class="p">}</span>
<span class="p">]</span>

<span class="n">messages</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">conversation_json</span><span class="p">)</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
	<span class="n">user_input</span> <span class="o">=</span> <span class="nf">input</span><span class="p">(</span><span class="sh">"</span><span class="s">Press quit or exit to quit</span><span class="se">\n\n</span><span class="s">User: </span><span class="sh">"</span><span class="p">)</span>
	<span class="k">if</span> <span class="n">user_input</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">exit</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">quit</span><span class="sh">"</span><span class="p">]:</span>
		<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Ending conversation.</span><span class="sh">"</span><span class="p">)</span>
		<span class="k">break</span>

	<span class="n">messages</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">user_input</span><span class="p">})</span>

	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">response</span> <span class="o">=</span> <span class="nf">pipe</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_full_text</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">generated_text</span><span class="sh">'</span><span class="p">]</span>

	<span class="n">messages</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">response</span><span class="p">})</span>

	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">AI: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> <hr/> <p><strong>Appendix</strong> <a href="https://chatgpt.com/g/g-wjwrMf1LL-emotions-stabilizer">https://chatgpt.com/g/g-wjwrMf1LL-emotions-stabilizer</a></p> <p><strong>Terms</strong> LLM (Large Language Model): A computer program trained on a lot of text data to understand and generate human-like language.</p> <p>World View: The perspective or way of thinking that influences how someone interprets information or generates content.</p> <p>Unstructured Data: Information like text, images, or videos that doesn’t follow a fixed format or structure, making it harder to organize and analyze.</p> <p>Dataset: A collection of related data used to train or test a machine learning model.</p> <p>GPT (Generative Pre-trained Transformer): A type of LLM developed by OpenAI that is trained to generate text by predicting the next word based on the context.</p> <p>Hugging Face: A company and platform offering tools and pre-trained models for working with LLMs, often open-source and easy to customize.</p> <p>OpenAI: The organization that created GPT models like ChatGPT. It focuses on building and deploying AI technologies.</p> <p>ChatGPT: A chatbot built using GPT, designed to interact with users conversationally by understanding and generating natural language.</p> <p>LLAMA (Large Language Model Meta AI): An LLM developed by Meta (Facebook’s parent company), focusing on being efficient and adaptable for research and applications.</p> <p>Microsoft Phi: A smaller LLM developed by Microsoft, known for being efficient while maintaining good performance.</p> <p>Training: The process of teaching an LLM by feeding it large amounts of data so it can learn patterns and relationships in language.</p> <p>Finetuning: A process where an already trained LLM is further trained on specific data to make it better at a particular task.</p> <p>Inference: Using a trained LLM to generate answers, predictions, or responses based on input from a user.</p> <p>Foundational LLM: A basic or core LLM trained on large general datasets, which can be further customized or used for various applications.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below. Together, we can navigate this evolving landscape and find our place in the future of work.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="llm"/><category term="AI"/><category term="future of work"/><category term="emerging technologies"/><category term="llm"/><summary type="html"><![CDATA[1. Executive Summary]]></summary></entry><entry><title type="html">How to self-learn Linux?</title><link href="https://lindathadeus.github.io/blog/2024/linux-self-learning/" rel="alternate" type="text/html" title="How to self-learn Linux?"/><published>2024-10-17T00:00:00+00:00</published><updated>2024-10-17T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/linux-self-learning</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/linux-self-learning/"><![CDATA[<h1 id="linux-kernel-development-self-learning-curriculum">Linux Kernel Development Self-Learning Curriculum</h1> <p>This Curriculum is created by the REASONING AI, ChatGPT-o1 (The Strawberry AI).</p> <p><strong>Prerequisites</strong> Before diving into kernel development, ensure you have a solid understanding of:</p> <p><strong>Linux Fundamentals</strong></p> <ul> <li>Command-line proficiency</li> <li>Basic system administration</li> </ul> <p><strong>Programming Skills</strong></p> <ul> <li>Proficient in C programming</li> <li>Familiarity with data structures and algorithms</li> <li>Operating Systems Concepts</li> <li>Processes, memory management, file systems, networking basics</li> </ul> <ol> <li>Introduction to Linux Kernel Development Linux Kernel Architecture Monolithic vs. Microkernel Kernel space vs. User space Kernel Versions and Releases Understanding stable, mainline, and long-term support (LTS) kernels Setting Up a Development Environment Installing necessary tools (gcc, make, git) Configuring and building the kernel from source Using virtualization tools like QEMU or VMware for testing</li> <li>Advanced C Programming for Kernel Development Kernel Coding Style Linux kernel coding guidelines (Documentation/process/coding-style.rst) Pointers and Memory Management Pointer arithmetic, memory allocation (kmalloc, kfree) Data Structures in the Kernel Linked lists, trees, queues Concurrency and Synchronization Volatile keyword, memory barriers</li> <li>Kernel Modules and Device Drivers Writing Kernel Modules Creating simple modules (init and exit functions) Compiling and inserting modules (insmod, rmmod, modprobe) Character Device Drivers Implementing open, read, write, close operations Block Device Drivers Understanding block I/O operations Device Model and sysfs Interacting with device attributes</li> <li>Kernel Debugging Techniques Logging and Debugging Using printk, log levels, and dmesg Kernel Debuggers Using kgdb, kdb, and GDB for kernel debugging Analyzing Kernel Crashes Setting up kdump and crash utilities Tracing and Profiling Tools Using ftrace, perf, eBPF</li> <li>Source Code Management with Git Cloning the Linux Kernel Source Using git to clone repositories from kernel.org Understanding the Kernel Source Tree Navigating directories and understanding code organization Submitting Patches Generating patches with git format-patch Sending patches via email (git send-email) Linux Kernel Mailing List (LKML) Participating in discussions and code reviews</li> <li>File System Development (FS Expertise) Introduction to File Systems Overview of ext2/3/4, XFS, Btrfs, etc. Virtual File System (VFS) Layer Understanding the VFS abstraction Key structures: inode, dentry, super_block, file_operations Implementing a Simple File System Creating a basic file system (e.g., a RAM-based file system) File System Operations Implementing methods like read, write, open, release File System Caching and Buffers Page cache, buffer heads Advanced File System Concepts Journaling mechanisms Transaction management File system consistency and recovery</li> <li>Networking Stack Development (Networking Expertise) Linux Networking Architecture OSI model layers in the kernel Netlink sockets, socket buffers (sk_buff) Network Device Drivers Writing Ethernet drivers NAPI (New API) for network drivers Protocol Implementation Implementing or modifying TCP/IP stack components Working with transport protocols Netfilter Framework Packet filtering, NAT, connection tracking Network Namespaces and Virtualization Implementing network isolation Traffic Control and QoS Understanding tc, queuing disciplines</li> <li>Synchronization and Concurrency in the Kernel Atomic Operations Using atomic variables and operations Synchronization Primitives Spinlocks, mutexes, semaphores, completion variables Locking Strategies Deadlock avoidance, lock ordering Read-Copy Update (RCU) Understanding RCU mechanisms and use-cases</li> <li>Memory Management Subsystem Physical and Virtual Memory Address translation, paging mechanisms Memory Zones and Allocation ZONE_DMA, ZONE_NORMAL, ZONE_HIGHMEM Slab Allocator Working with kmem_cache Page Cache and Swapping Managing page cache, swap space interactions</li> <li>Process Management and Scheduling Process Descriptor and Task Structure Understanding task_struct Process Lifecycle Creation (fork, exec), scheduling, termination Kernel Threads Creating and managing kernel threads Scheduling Algorithms Completely Fair Scheduler (CFS), real-time scheduling policies Timers and Scheduling Latency High-resolution timers, jiffies, delays</li> <li>Inter-Process Communication in the Kernel Signals Handling signals in kernel space Wait Queues Implementing sleep and wake-up mechanisms Notifiers and Callbacks Using notifier chains for event handling</li> <li>Security in the Kernel Linux Security Modules (LSM) Overview of SELinux, AppArmor Capability Systems Dropping and checking capabilities Secure Coding Practices Avoiding common pitfalls (buffer overflows, integer overflows)</li> <li>Kernel Configuration and Build System Kernel Configuration Tools Using make menuconfig, xconfig Kernel Build Process Understanding Makefiles and Kconfig files Cross-Compilation Building kernels for different architectures</li> <li>Contributing to the Linux Kernel Kernel Development Process Understanding the contribution workflow Coding Standards Compliance Using checkpatch.pl to validate code style Legal Considerations GPL licensing, developer’s Certificate of Origin Maintainers and Subsystems Working with subsystem maintainers for patch acceptance</li> <li>Advanced Topics Real-Time Linux PREEMPT_RT patch, real-time scheduling Kernel Virtualization Technologies KVM, Xen integration in the kernel Device Tree Usage Understanding and writing device tree blobs for hardware Methodology for Effective Self-Learning</li> <li>Structured Learning Approach Progressive Learning Start with foundational concepts before moving to advanced topics. Set Clear Goals Define what you aim to achieve (e.g., write a basic file system module).</li> <li>Hands-On Practice Set Up a Development Lab Use virtual machines or spare hardware for kernel testing. Kernel Compilation and Testing Regularly build and boot custom kernels. Code Exploration Read existing kernel code to understand implementations.</li> <li>Utilize Multiple Resources Books “Linux Kernel Development” by Robert Love “Understanding the Linux Kernel” by Daniel P. Bovet and Marco Cesati “Linux Device Drivers” by Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman Online Documentation The Linux Kernel Archives: kernel.org Kernel Newbies: kernelnewbies.org Linux Cross Reference: elixir.bootlin.com Tutorials and Guides The Linux Kernel Module Programming Guide Linux Device Drivers Tutorial by Derek Molloy Mailing Lists and Forums Linux Kernel Mailing List (LKML) Stack Overflow, Reddit’s r/kernel</li> <li>Engage with the Community Participate in Discussions Join IRC channels like #kernel on Freenode. Contribute to Projects Start with small bug fixes or documentation improvements. Attend Conferences and Workshops Linux Foundation events, local meetups.</li> <li>Apply Knowledge to Projects File System Project Implement a simple file system (e.g., a memory-based file system). Networking Project Modify or extend a network protocol implementation. Device Driver Development Write drivers for virtual or actual hardware devices.</li> <li>Regular Assessment Code Reviews Seek feedback from experienced developers on your code. Self-Evaluation Reflect on what you’ve learned after completing each topic. Mentorship Consider finding a mentor in the kernel community.</li> <li>Stay Updated Follow Kernel Development News Read LWN.net for updates and articles. Track Mailing Lists Stay informed about discussions on LKML. Additional Tips Consistency and Patience Kernel development is complex; consistent effort is crucial. Attention to Detail Small mistakes can have significant impacts; double-check your work. Understand Before Coding Spend time understanding the existing codebase before making changes. Documentation Keep notes and document your learning journey. By following this curriculum and methodology, you’ll develop a deep understanding of Linux kernel internals, particularly in file systems and networking. This will prepare you for contributing to the kernel community and pursuing a career in kernel development.</li> </ol> <p><strong>Recommended Learning Path</strong> Start with the basics: Ensure your C programming skills are solid, and you understand operating systems concepts. Set up your environment: Build and boot a custom kernel. Learn by doing: Begin writing simple kernel modules. Dive into file systems: Study the VFS layer and implement a basic file system. Explore networking: Understand the networking stack and experiment with network modules. Contribute to the community: Start small by fixing bugs or improving documentation. Remember, kernel development requires a strong commitment to learning and adherence to community standards. Engaging with the community will not only enhance your learning but also open up opportunities for collaboration and mentorship.</p> <p><strong>How to add comments to the static site?</strong> Using Github discussion API and giscus-app, Follow the below <a href="https://www.patrickthurmond.com/blog/2023/12/11/commenting-is-available-now-thanks-to-giscus/"> tutorial</a></p> <p>Hope, you could set it up too :) Stay tuned for more!</p>]]></content><author><name></name></author><category term="meaning"/><category term="linux"/><category term="linux"/><summary type="html"><![CDATA[Linux Kernel Development Self-Learning Curriculum]]></summary></entry><entry><title type="html">Worthy Word #2 Securely Attached</title><link href="https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached/" rel="alternate" type="text/html" title="Worthy Word #2 Securely Attached"/><published>2024-10-08T00:00:00+00:00</published><updated>2024-10-08T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/worthy-word-securely-attached/"><![CDATA[<h3 id="secured-attachment">Secured Attachment</h3> <p>In recent reflections, I’ve been diving into attachment styles and how they shape our communication and relationships. One key insight I’ve discovered is that securely attached people are often quicker to communicate and regulate themselves emotionally compared to those with avoidant or anxious attachment styles.</p> <p>It became clear during this journey that securely attached people “talk it out,” while avoidants avoid, and anxious individuals tend to do the talking in their heads. But is this just a matter of communication skills? Here’s how the conversation unfolded:</p> <p>Linda: “All along, I had thought I was at a disadvantage for being a non-securely attached person. But now it looks like, if verbal communication had been encouraged more, we too could become securely attached.”</p> <p>ChatGPT: “That’s a great realization! Communication is a key part of secure attachment. Avoidant and anxious individuals often struggle with verbal communication, but with the right support, like a communication enhancer, they can build healthier habits.”</p> <p>Linda: “During school, I noticed that securely attached people did not choose me because I wasn’t as verbally communicative. I see now that I need to be faster and more verbally open to become securely attached.”</p> <p>ChatGPT: “Exactly! It’s not about changing who you are but rather developing skills that make communication more fluid. Being verbally communicative—clear, intentional, and open—is part of what makes securely attached individuals thrive.”</p> <p>One important takeaway from our exchange is that attachment styles aren’t permanent. They can evolve through the development of key communication skills. Both avoidant and anxious individuals may struggle because they aren’t confident in their ability to express themselves effectively. But with practice, they can improve how they handle communication in relationships.</p> <p>This led me to reflect further: If caregivers had communicated more verbally with children, the child would likely have been more verbally communicative in return, avoiding some of the challenges tied to avoidant or anxious attachment styles.</p> <p>Linda: “It’s all because of physical appearance—self-confidence issues during childhood. That was why I didn’t speak much. But avoidant individuals in general, why did they become avoidant?”</p> <p>ChatGPT: “You’re right—attachment styles develop from various reasons, often tied to the emotional environment during childhood. Lack of verbal communication and emotional responsiveness from caregivers can lead to avoidant attachment, as the child may learn that expressing emotions won’t result in support.”</p> <p>Linda: “Yes, it appears that if caregivers had been verbally communicative, the child would’ve learned to communicate better. So, avoidants aren’t well-versed in communication, and anxious individuals fear that speaking up might make things worse.”</p> <p>ChatGPT: “Exactly, avoidants often think avoidance is better than communicating, while anxious individuals fear that communicating incorrectly will worsen things. Both are rooted in a lack of confidence in communication skills.”</p> <p>So, what’s missing for non-securely attached individuals? It seems clear now that it’s effective, confident, and intentional communication that they need to build. This insight offers hope—by improving communication skills, anyone can start moving toward secure attachment.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="philosophy"/><category term="graceful-bonding"/><category term="world"/><category term="grace"/><category term="general"/><summary type="html"><![CDATA[Secured Attachment]]></summary></entry><entry><title type="html">Debugging Keyboard events in Sony Laptop</title><link href="https://lindathadeus.github.io/blog/2024/key-debugging/" rel="alternate" type="text/html" title="Debugging Keyboard events in Sony Laptop"/><published>2024-10-06T00:00:00+00:00</published><updated>2024-10-06T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/key-debugging</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/key-debugging/"><![CDATA[<h3 id="diagnosing-and-checking-key-events-in-my-old-sony-laptop">Diagnosing and Checking Key Events in My Old Sony Laptop</h3> <p>It wasn’t even a day—actually just a few hours—after I finally gave a purpose to my old Sony Laptop and updated its kernel for daily use when I noticed that the up arrow key wasn’t working.</p> <p>At first, I thought I’d wasted all that time on a machine that I should probably just condemn. But there was something more at play—this wasn’t just any laptop. It was a gift from my mom, my pink laptop with my name engraved on it. The emotional value was enough to keep me going. I couldn’t give up on it that easily!</p> <h4 id="debugging-the-problem">Debugging the Problem</h4> <p>Since I’d spent so much time already, I figured I’d start debugging. I created an event notifier for keyboard events using the following kernel module:</p> <figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">int</span> <span class="nf">notifier</span><span class="p">(</span><span class="k">struct</span> <span class="n">notifier_block</span> <span class="o">*</span><span class="n">nblock</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">code</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">_param</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">keyboard_notifier_param</span> <span class="o">*</span><span class="n">param</span> <span class="o">=</span> <span class="n">_param</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">code</span> <span class="o">==</span> <span class="n">KBD_KEYCODE</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printk</span><span class="p">(</span><span class="n">KERN_INFO</span> <span class="s">"Key press: scancode = %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">param</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">NOTIFY_OK</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="k">struct</span> <span class="n">notifier_block</span> <span class="n">nb</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">.</span><span class="n">notifier_call</span> <span class="o">=</span> <span class="n">notifier</span>
<span class="p">};</span></code></pre></figure> <p>The idea was to capture and log any key events. Pressing the up arrow…nothing. Sigh.</p> <h4 id="physical-troubleshooting">Physical Troubleshooting</h4> <p>I tried something else. I removed the key, dusted it off, cleaned everything, and reattached it. Still no events. Another sigh.</p> <p>Then, in what felt like a desperate attempt, I removed the key once again. At this point, I was sure I’d broken something—both the key and my heart. But before giving up completely, I tried pressing the actual rubber underneath the key that triggers the event.</p> <p>Success! Events were detected, but only when pressing the rubber directly—not with the key attached.</p> <h4 id="the-final-temporary-fix">The Final (Temporary) Fix</h4> <p>With a bit of cello tape (yes, you read that right), I reattached the key to the keyboard. It’s not perfect, but it works—kind of. In the end, I’m using SSH to access my Sony laptop, but at least I know the up key is functional. And even if I don’t use it, just knowing it’s working gives me a sense of relief.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="linux"/><category term="work"/><category term="world"/><category term="sony"/><category term="general"/><summary type="html"><![CDATA[Diagnosing and Checking Key Events in My Old Sony Laptop]]></summary></entry><entry><title type="html">Compiling Linux for Sony Laptop from a ThinkPad</title><link href="https://lindathadeus.github.io/blog/2024/linux-compilation/" rel="alternate" type="text/html" title="Compiling Linux for Sony Laptop from a ThinkPad"/><published>2024-10-05T00:00:00+00:00</published><updated>2024-10-05T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/linux-compilation</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/linux-compilation/"><![CDATA[<h3 id="linux-cross-compilation">Linux Cross Compilation</h3> <p>Introduction</p> <p>As technology enthusiasts and developers, we sometimes encounter old hardware that still works well but needs a refresh. Recently, I decided to give my trusty old Sony laptop a second life by cross-compiling the Linux kernel on my ThinkPad and running it on the Sony laptop. The experience helped me learn more about cross-compilation, hardware compatibility, and Linux customization.</p> <p>In this post, I will walk you through the steps of how I compiled a custom Linux kernel for my Sony laptop from my ThinkPad.</p> <p>Step 1: Setting Up the Build Environment on the ThinkPad</p> <p>The first step in cross-compiling the Linux kernel was to set up the appropriate build environment on my ThinkPad. This included installing essential tools like gcc, make, and cross-compilation tools for the x86_64 architecture.</p> <p>To begin, I used the following commands:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">build</span><span class="o">-</span><span class="n">essential</span> <span class="n">libncurses</span><span class="o">-</span><span class="n">dev</span> <span class="n">bison</span> <span class="n">flex</span> <span class="n">libssl</span><span class="o">-</span><span class="n">dev</span> <span class="n">libelf</span><span class="o">-</span><span class="n">dev</span></code></pre></figure> <p>Step 2: Downloading the Linux Kernel Source Code</p> <p>I then downloaded the latest Linux kernel source code. I chose the version that would be suitable for my Sony laptop’s hardware and started configuring the kernel for compilation:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">cdn</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">pub</span><span class="o">/</span><span class="n">linux</span><span class="o">/</span><span class="n">kernel</span><span class="o">/</span><span class="n">v6</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="n">linux</span><span class="o">-</span><span class="mf">6.11</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">xz</span>
<span class="n">tar</span> <span class="o">-</span><span class="n">xvf</span> <span class="n">linux</span><span class="o">-</span><span class="mf">6.11</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">xz</span>
<span class="n">cd</span> <span class="n">linux</span><span class="o">-</span><span class="mf">6.11</span></code></pre></figure> <p>Step 3: Configuring the Kernel for the Sony Laptop</p> <p>Since I was compiling the kernel on my ThinkPad, I needed to ensure that the configuration was appropriate for the Sony laptop. I used the kernel configuration from the Sony laptop as a starting point:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">scp</span> <span class="n">user</span><span class="nd">@sony</span><span class="p">:</span><span class="o">/</span><span class="n">boot</span><span class="o">/</span><span class="n">config</span><span class="o">-&lt;</span><span class="n">version</span><span class="o">&gt;</span> <span class="p">.</span><span class="n">config</span>
<span class="n">make</span> <span class="n">ARCH</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">ARCH</span><span class="p">)</span> <span class="n">CROSS_COMPILE</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">CROSS_COMPILE</span><span class="p">)</span> <span class="n">O</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">KERNEL_BUILD_DIR</span><span class="p">)</span> <span class="o">-</span><span class="n">C</span> <span class="err">$</span><span class="p">(</span><span class="n">KERNEL_SRC_DIR</span><span class="p">)</span> <span class="n">olddefconfig</span></code></pre></figure> <p>This copied the kernel configuration from the Sony laptop and used it to adjust the new kernel for compatibility.</p> <p>Step 4: Cross-Compiling the Kernel</p> <p>To cross-compile the kernel, I used the following command:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">make</span> <span class="o">-</span><span class="n">j</span><span class="err">$$</span><span class="p">(</span><span class="n">nproc</span><span class="p">)</span> <span class="n">ARCH</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">ARCH</span><span class="p">)</span> <span class="n">CROSS_COMPILE</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">CROSS_COMPILE</span><span class="p">)</span> <span class="n">O</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">KERNEL_BUILD_DIR</span><span class="p">)</span> <span class="o">-</span><span class="n">C</span> <span class="err">$</span><span class="p">(</span><span class="n">KERNEL_SRC_DIR</span><span class="p">)</span></code></pre></figure> <p>This compiled the Linux kernel for the target architecture of the Sony laptop, while running the build process on my ThinkPad.</p> <p>Step 5: Transferring the Kernel to the Sony Laptop</p> <p>After the kernel was compiled, I packaged it into a tarball to transfer it over to the Sony laptop:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">tar</span> <span class="o">-</span><span class="n">czvf</span> <span class="n">kernel</span><span class="o">-</span><span class="n">package</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">gz</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">kernel</span><span class="o">/</span><span class="n">files</span>
<span class="n">scp</span> <span class="n">kernel</span><span class="o">-</span><span class="n">package</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">gz</span> <span class="n">user</span><span class="nd">@sony</span><span class="p">:</span><span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">sony</span><span class="o">/</span></code></pre></figure> <p>Step 6: Installing the Kernel on the Sony Laptop</p> <p>Once the kernel was transferred, I extracted it on the Sony laptop, copied the kernel and modules to the appropriate directories, and updated GRUB to reflect the new kernel:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">sudo</span> <span class="n">cp</span> <span class="n">vmlinuz</span> <span class="o">/</span><span class="n">boot</span><span class="o">/</span><span class="n">vmlinuz</span><span class="o">-</span><span class="mf">6.11</span><span class="p">.</span><span class="mi">0</span><span class="o">+</span>
<span class="n">sudo</span> <span class="n">cp</span> <span class="n">System</span><span class="p">.</span><span class="nb">map</span> <span class="o">/</span><span class="n">boot</span><span class="o">/</span><span class="n">System</span><span class="p">.</span><span class="nb">map</span><span class="o">-</span><span class="mf">6.11</span><span class="p">.</span><span class="mi">0</span><span class="o">+</span>
<span class="n">sudo</span> <span class="n">update</span><span class="o">-</span><span class="n">grub</span></code></pre></figure> <p>After rebooting, the Sony laptop was running the custom-compiled Linux kernel!</p> <p>Conclusion</p> <p>This experience of cross-compiling the Linux kernel on my ThinkPad and running it on the Sony laptop was both satisfying and informative. It breathed new life into the Sony laptop, and it reinforced how powerful Linux is when it comes to working with diverse hardware. If you have an older laptop lying around, consider giving it a second life with a custom Linux kernel!</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="linux"/><category term="work"/><category term="world"/><category term="sony"/><category term="general"/><summary type="html"><![CDATA[Linux Cross Compilation]]></summary></entry><entry><title type="html">AI Conversations: Actions and Words and Thoughts</title><link href="https://lindathadeus.github.io/blog/2024/actions-trump-intentions/" rel="alternate" type="text/html" title="AI Conversations: Actions and Words and Thoughts"/><published>2024-09-29T00:00:00+00:00</published><updated>2024-09-29T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/actions-trump-intentions</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/actions-trump-intentions/"><![CDATA[<h3 id="actions-thoughts-and-words---a-dialogue">Actions, Thoughts, and Words - a Dialogue</h3> <p><strong>Linda:</strong> If words and thoughts (intentions) are multipliers of actions, then why do we concentrate so much on the intentions behind actions?</p> <p><strong>ChatGPT:</strong> Intentions give us a window into the motivations driving those actions. While actions are visible and tangible, intentions help us understand the “why” behind them, giving context. Without understanding intentions, actions may sometimes be misinterpreted.</p> <p><strong>Linda:</strong> I agree, but I think intentions can also be used to justify bad deeds. That’s why I feel actions should carry more weight. Intentions are abstract; actions are what leave a mark.</p> <p><strong>ChatGPT:</strong> That’s a strong point. In the physical world, actions result in real consequences, whether intended or not. So, we often judge actions based on their outcome, not just the thought behind them.</p> <p><strong>Linda:</strong> Exactly. In the physical world, actions need to be given more weight. However, in higher realms like words, thoughts, or emotions, both actions and intentions are relevant. But even there, actions carry more weight than intentions.</p> <p><strong>ChatGPT:</strong> I see the distinction you’re making. In higher realms, intentions and thoughts guide the energy behind actions, but at the end of the day, the actions themselves are still the most powerful force.</p> <p><strong>Linda:</strong> Yes, I believe so. Words and thoughts are more fluid, but actions crystallize everything into reality. You can’t hide behind intentions when your actions have already created an outcome.</p> <p><strong>ChatGPT:</strong> It’s true. In essence, while intentions provide direction and purpose, it’s the actions that ultimately define the reality we live in.</p> <p><strong>Linda:</strong> Exactly! So, while both are important, actions in the physical world are what truly matter. And when words and thoughts come into play, the balance is different, but still, actions speak louder than intentions.</p> <p><strong>ChatGPT:</strong> A wise conclusion. Intentions may guide, but actions have the final say in how we affect the world.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="philosophy"/><category term="llm"/><category term="grace"/><category term="world"/><category term="words"/><category term="general"/><summary type="html"><![CDATA[Actions, Thoughts, and Words - a Dialogue]]></summary></entry><entry><title type="html">Scarcity to Abundance: Our Revolutions</title><link href="https://lindathadeus.github.io/blog/2024/revolution-sequence/" rel="alternate" type="text/html" title="Scarcity to Abundance: Our Revolutions"/><published>2024-09-24T00:00:00+00:00</published><updated>2024-09-24T00:00:00+00:00</updated><id>https://lindathadeus.github.io/blog/2024/revolution-sequence</id><content type="html" xml:base="https://lindathadeus.github.io/blog/2024/revolution-sequence/"><![CDATA[<h2 id="how-humanity-evolved-from-scarcity-to-abundance">How Humanity Evolved from Scarcity to Abundance</h2> <p>Throughout history, humanity has transitioned from scarcity to abundance, each revolution removing key limitations and generating new demands. Here’s a quick overview of this journey:</p> <h3 id="1-small-scale-agriculture">1. Small-Scale Agriculture</h3> <ul> <li><strong>Abundance Created:</strong> Survival skills, basic tools, and money.</li> <li><strong>Scarcity Removed:</strong> High mortality.</li> <li><strong>New Demand:</strong> Food production and human muscle power (mechanical energy).</li> </ul> <p>Early human-beings used to be hunter-gatherers, with hunter-men leaving their women and children for hunting for a longer distance and most times never returned because of some animal attack or they found some other women from the tribe. The survival rate of them were very less on an average. But, all this changed when human beings discovered AGRICULTURE. Women and children were able to manage surviving without the men. They did not have to go into the woods for GATHERING food. Even there was a reduced need for Hunting as Human-beings started DOMESTICATION of animals like sheeps, pigs, buffaloes and used them instead of HUNTING. This reduced the MORTALITY of human-beings. Agricultural practices involved using simple mechanical tools and used manual-labourers. They selectively bred animal and cultivated and nurtured digestible food-crops.</p> <h3 id="2-agricultural-revolution">2. Agricultural Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Food surplus and population growth.</li> <li><strong>Scarcity Removed:</strong> Food scarcity.</li> <li><strong>New Demand:</strong> Tools and mechanical energy at scale to increase productivity.</li> </ul> <p>With the advent of Agriculture, the survival rate increased and suddenly the population exploded giving rise to all higher level problems (when compared to MORTALITY) like, WEALTH-INEQUALITY, SLAVERY, CASTEISM, RACISM. But, people who were not subject to the higher level problems faced the MORTALITY. There came a need for increased food production for feeding the ever growing population and selective people with the agricultural knowledge took advantage of the non-knowledgable using SLAVERY so as to maximize the PROFITS. Then came the GREEN REVOLUTION with the genetically modified seeds, the YIELD/PROFITS became too HIGH eradicating the need for SLAVERY. Suddenly, the human muscle energy became too less. Thus, the need for BETTER TOOLS for TRANSPORTATION of the crops from one place to another and etc.</p> <h3 id="3-industrial-revolution">3. Industrial Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Machinery powered by fossil fuels.</li> <li><strong>Scarcity Removed:</strong> Labor scarcity in production.</li> <li><strong>New Demand:</strong> Inventory management, faster communication, and large-scale energy supply.</li> </ul> <p>The demand of transportation of the newly found Agricultural Revolution gave birth to HIGH YIELD Crops that would have to be PRESERVED, TRANSPORTED to far away lands, MANAGED naturally wanted a revolution in the vehicles and energy. At this time, SLAVERY was getting abolished and people’s earlier skills were nullified and essentially equalised the playing field, thus as a side-effect abolishing slavery. The steam powered railway engines moved to FOSSIL-FUEL powered HIGH-PERFORMANCE railway/ship engines that were faster to transport the finished goods from one place to another. The GOODS manufactured were too high that we had to create software in-place to manage them, talk with clients globally.</p> <h3 id="4-it-revolution">4. IT Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Data and digital technologies.</li> <li><strong>Scarcity Removed:</strong> Knowledge scarcity.</li> <li><strong>New Demand:</strong> Data management, accessibility, and intelligence skills at scale.</li> </ul> <p>The demand for software to manage and communicate resulted in generation of too many digital content waiting to be consumed by people to become knowledgeable and thus creating an EQUALIZER.</p> <h3 id="5-education-revolution">5. Education Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Skills and education.</li> <li><strong>Scarcity Removed:</strong> Skill scarcity.</li> <li><strong>New Demand:</strong> AI skills management/accessibility, renewable energy, and computing power at scale.</li> </ul> <p>As more people gained access to education, the Education Revolution helped eliminate skill scarcity. The global workforce became more knowledgeable, leading to a demand for AI educator at scale, renewable energy solutions, and computing power to sustain the growing technological infrastructure. AI products are the abundance created.</p> <h3 id="6-ai-revolution">6. AI Revolution</h3> <ul> <li><strong>Abundance Created:</strong> Intelligent systems and automation.</li> <li><strong>Scarcity Removed:</strong> Cognitive labor scarcity.</li> <li><strong>New Demand:</strong> Ethical AI frameworks, human-AI collaboration, sustainable energy, physical body form for AI, biological integration.</li> </ul> <p>Next is the AI Revolution, which too like the previous revolution will be an EQUALIZER of the AI products. Everyone could and would own an AI. The Ethical AI Agent would be the Leader. They would remove the previous scarcity that would be Management of AI products.</p> <hr/> <p><strong>What do you think?</strong> Let me know your thoughts in the comments below.</p>]]></content><author><name>Linda Joe Thadeus</name></author><category term="llm"/><category term="llm"/><category term="world"/><category term="general"/><category term="history"/><category term="hallucination-or-revalation"/><summary type="html"><![CDATA[How Humanity Evolved from Scarcity to Abundance]]></summary></entry></feed>